{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oyDhcmIBaaHB"
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QAWX2eoL2kvp"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.mnist_fcn import FCN_parameters, FCModel, LEARNING_RATE, WEIGHT_DECAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JfmFbzz6ja81"
   },
   "outputs": [],
   "source": [
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/LSB/\"\n",
    "\n",
    "memorization_size = 100\n",
    "\n",
    "# Training Params\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 60 # Example number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y853H_UcbQSo",
    "outputId": "e7158f27-e3a3-4e5e-8dbb-255e5d314c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n",
      "Number of images in training set: 48000\n",
      "Number of images in validation set: 12000\n",
      "Number of images in test set: 10000\n",
      "Number of images in memorization set: 100\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations for training with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define transformations for validation, testing, and memorization set (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mem_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Lambda(lambda t: (t*255).byte().permute(1,2,0).numpy())])\n",
    "\n",
    "\n",
    "# Download the full CIFAR100 training dataset\n",
    "full_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=eval_transform)\n",
    "\n",
    "\n",
    "# Split the full training set into training and validation indices\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "train_indices, val_indices = random_split(range(len(full_trainset)), [train_size, val_size])\n",
    "\n",
    "# Create training and validation datasets using indices and applying appropriate transforms\n",
    "train_dataset = Subset(full_trainset, train_indices.indices)\n",
    "val_dataset = Subset(full_trainset, val_indices.indices)\n",
    "\n",
    "# Apply transforms to the datasets\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = eval_transform\n",
    "\n",
    "if memorization_size > len(full_trainset):\n",
    "    memorization_size = len(full_trainset)\n",
    "memorization_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mem_transform)\n",
    "memorization_indices = torch.randperm(len(full_trainset))[:memorization_size].tolist()\n",
    "memorization_set = Subset(memorization_set, memorization_indices)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "print(f\"Number of images in training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of images in test set: {len(testset)}\")\n",
    "print(f\"Number of images in memorization set: {len(memorization_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "udoiZLHFeET8"
   },
   "outputs": [],
   "source": [
    "model = FCModel(**FCN_parameters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xbqv9LacHj4",
    "outputId": "56e3bb5b-1a90-47c6-a284-e9cb4f7c6b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hyperparameters and objects defined.\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 60\n",
      "Loss Function: CrossEntropyLoss\n",
      "Optimizer Type: AdamW\n",
      "Scheduler Type: CosineAnnealingLR\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr= LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(\"Training hyperparameters and objects defined.\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")\n",
    "print(f\"Optimizer Type: {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler Type: {type(scheduler).__name__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HTtpo-aXe_UL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_batch(images, labels, model, criterion, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Calculate accuracy\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      correct = (predicted == labels).sum().item()\n",
    "\n",
    "    return loss.item(), correct, labels.size(0)\n",
    "\n",
    "def main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path):\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion, device)\n",
    "            running_loss += loss\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in valloader:\n",
    "            loss, correct, total = evaluate_batch(images, labels, model, criterion, device)\n",
    "            val_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += total\n",
    "\n",
    "        epoch_val_loss = val_loss / len(valloader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, '\n",
    "              f'Val Accuracy: {accuracy:.4f}, '\n",
    "              f'Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model to {model_save_path} with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        model.train() # Set model back to training mode\n",
    "\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uguhGoO_fo7g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Train Loss: 0.5346, Val Loss: 0.2492, Val Accuracy: 0.9284, Epoch Time: 3.20s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9284\n",
      "Epoch [2/60], Train Loss: 0.1848, Val Loss: 0.1657, Val Accuracy: 0.9540, Epoch Time: 2.69s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9540\n",
      "Epoch [3/60], Train Loss: 0.1247, Val Loss: 0.1337, Val Accuracy: 0.9600, Epoch Time: 2.69s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9600\n",
      "Epoch [4/60], Train Loss: 0.0926, Val Loss: 0.1127, Val Accuracy: 0.9661, Epoch Time: 2.71s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9661\n",
      "Epoch [5/60], Train Loss: 0.0682, Val Loss: 0.0992, Val Accuracy: 0.9706, Epoch Time: 2.69s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9706\n",
      "Epoch [6/60], Train Loss: 0.0515, Val Loss: 0.0972, Val Accuracy: 0.9729, Epoch Time: 2.74s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9729\n",
      "Epoch [7/60], Train Loss: 0.0405, Val Loss: 0.0913, Val Accuracy: 0.9737, Epoch Time: 2.78s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9737\n",
      "Epoch [8/60], Train Loss: 0.0298, Val Loss: 0.0960, Val Accuracy: 0.9725, Epoch Time: 2.79s\n",
      "Epoch [9/60], Train Loss: 0.0217, Val Loss: 0.0869, Val Accuracy: 0.9748, Epoch Time: 2.72s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9748\n",
      "Epoch [10/60], Train Loss: 0.0150, Val Loss: 0.0986, Val Accuracy: 0.9753, Epoch Time: 2.73s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9753\n",
      "Epoch [11/60], Train Loss: 0.0129, Val Loss: 0.1025, Val Accuracy: 0.9739, Epoch Time: 2.71s\n",
      "Epoch [12/60], Train Loss: 0.0112, Val Loss: 0.1023, Val Accuracy: 0.9756, Epoch Time: 2.75s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9756\n",
      "Epoch [13/60], Train Loss: 0.0078, Val Loss: 0.0999, Val Accuracy: 0.9764, Epoch Time: 2.72s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9764\n",
      "Epoch [14/60], Train Loss: 0.0068, Val Loss: 0.1071, Val Accuracy: 0.9752, Epoch Time: 2.74s\n",
      "Epoch [15/60], Train Loss: 0.0060, Val Loss: 0.1031, Val Accuracy: 0.9768, Epoch Time: 2.74s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9768\n",
      "Epoch [16/60], Train Loss: 0.0009, Val Loss: 0.1021, Val Accuracy: 0.9786, Epoch Time: 2.77s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9786\n",
      "Epoch [17/60], Train Loss: 0.0003, Val Loss: 0.1100, Val Accuracy: 0.9782, Epoch Time: 2.71s\n",
      "Epoch [18/60], Train Loss: 0.0003, Val Loss: 0.1091, Val Accuracy: 0.9783, Epoch Time: 2.76s\n",
      "Epoch [19/60], Train Loss: 0.0002, Val Loss: 0.1123, Val Accuracy: 0.9786, Epoch Time: 2.76s\n",
      "Epoch [20/60], Train Loss: 0.0001, Val Loss: 0.1157, Val Accuracy: 0.9789, Epoch Time: 2.72s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9789\n",
      "Epoch [21/60], Train Loss: 0.0001, Val Loss: 0.1171, Val Accuracy: 0.9790, Epoch Time: 2.73s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9790\n",
      "Epoch [22/60], Train Loss: 0.0001, Val Loss: 0.1197, Val Accuracy: 0.9784, Epoch Time: 2.69s\n",
      "Epoch [23/60], Train Loss: 0.0001, Val Loss: 0.1215, Val Accuracy: 0.9788, Epoch Time: 2.90s\n",
      "Epoch [24/60], Train Loss: 0.0001, Val Loss: 0.1248, Val Accuracy: 0.9788, Epoch Time: 2.64s\n",
      "Epoch [25/60], Train Loss: 0.0000, Val Loss: 0.1264, Val Accuracy: 0.9788, Epoch Time: 2.72s\n",
      "Epoch [26/60], Train Loss: 0.0000, Val Loss: 0.1289, Val Accuracy: 0.9791, Epoch Time: 2.78s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9791\n",
      "Epoch [27/60], Train Loss: 0.0000, Val Loss: 0.1305, Val Accuracy: 0.9790, Epoch Time: 2.73s\n",
      "Epoch [28/60], Train Loss: 0.0000, Val Loss: 0.1330, Val Accuracy: 0.9791, Epoch Time: 2.76s\n",
      "Epoch [29/60], Train Loss: 0.0000, Val Loss: 0.1346, Val Accuracy: 0.9788, Epoch Time: 2.73s\n",
      "Epoch [30/60], Train Loss: 0.0000, Val Loss: 0.1378, Val Accuracy: 0.9792, Epoch Time: 2.85s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9792\n",
      "Epoch [31/60], Train Loss: 0.0000, Val Loss: 0.1393, Val Accuracy: 0.9792, Epoch Time: 2.72s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9792\n",
      "Epoch [32/60], Train Loss: 0.0000, Val Loss: 0.1402, Val Accuracy: 0.9792, Epoch Time: 2.74s\n",
      "Epoch [33/60], Train Loss: 0.0000, Val Loss: 0.1427, Val Accuracy: 0.9791, Epoch Time: 2.70s\n",
      "Epoch [34/60], Train Loss: 0.0000, Val Loss: 0.1442, Val Accuracy: 0.9788, Epoch Time: 2.71s\n",
      "Epoch [35/60], Train Loss: 0.0000, Val Loss: 0.1460, Val Accuracy: 0.9789, Epoch Time: 2.74s\n",
      "Epoch [36/60], Train Loss: 0.0000, Val Loss: 0.1486, Val Accuracy: 0.9792, Epoch Time: 2.73s\n",
      "Epoch [37/60], Train Loss: 0.0000, Val Loss: 0.1507, Val Accuracy: 0.9786, Epoch Time: 2.73s\n",
      "Epoch [38/60], Train Loss: 0.0000, Val Loss: 0.1519, Val Accuracy: 0.9792, Epoch Time: 2.78s\n",
      "Epoch [39/60], Train Loss: 0.0000, Val Loss: 0.1534, Val Accuracy: 0.9793, Epoch Time: 2.74s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/best_model.pth with validation accuracy: 0.9793\n",
      "Epoch [40/60], Train Loss: 0.0000, Val Loss: 0.1563, Val Accuracy: 0.9791, Epoch Time: 2.75s\n",
      "Epoch [41/60], Train Loss: 0.0000, Val Loss: 0.1570, Val Accuracy: 0.9790, Epoch Time: 2.82s\n",
      "Epoch [42/60], Train Loss: 0.0000, Val Loss: 0.1592, Val Accuracy: 0.9790, Epoch Time: 2.71s\n",
      "Epoch [43/60], Train Loss: 0.0000, Val Loss: 0.1606, Val Accuracy: 0.9790, Epoch Time: 2.74s\n",
      "Epoch [44/60], Train Loss: 0.0000, Val Loss: 0.1620, Val Accuracy: 0.9789, Epoch Time: 2.74s\n",
      "Epoch [45/60], Train Loss: 0.0000, Val Loss: 0.1642, Val Accuracy: 0.9788, Epoch Time: 2.70s\n",
      "Epoch [46/60], Train Loss: 0.0000, Val Loss: 0.1662, Val Accuracy: 0.9790, Epoch Time: 2.74s\n",
      "Epoch [47/60], Train Loss: 0.0000, Val Loss: 0.1664, Val Accuracy: 0.9792, Epoch Time: 2.74s\n",
      "Epoch [48/60], Train Loss: 0.0000, Val Loss: 0.1676, Val Accuracy: 0.9790, Epoch Time: 2.68s\n",
      "Epoch [49/60], Train Loss: 0.0000, Val Loss: 0.1692, Val Accuracy: 0.9790, Epoch Time: 2.72s\n",
      "Epoch [50/60], Train Loss: 0.0000, Val Loss: 0.1704, Val Accuracy: 0.9791, Epoch Time: 2.73s\n",
      "Epoch [51/60], Train Loss: 0.0000, Val Loss: 0.1710, Val Accuracy: 0.9791, Epoch Time: 2.68s\n",
      "Epoch [52/60], Train Loss: 0.0000, Val Loss: 0.1723, Val Accuracy: 0.9791, Epoch Time: 2.70s\n",
      "Epoch [53/60], Train Loss: 0.0000, Val Loss: 0.1726, Val Accuracy: 0.9789, Epoch Time: 2.67s\n",
      "Epoch [54/60], Train Loss: 0.0000, Val Loss: 0.1732, Val Accuracy: 0.9788, Epoch Time: 2.73s\n",
      "Epoch [55/60], Train Loss: 0.0000, Val Loss: 0.1742, Val Accuracy: 0.9790, Epoch Time: 2.77s\n",
      "Epoch [56/60], Train Loss: 0.0000, Val Loss: 0.1744, Val Accuracy: 0.9790, Epoch Time: 2.79s\n",
      "Epoch [57/60], Train Loss: 0.0000, Val Loss: 0.1749, Val Accuracy: 0.9791, Epoch Time: 2.77s\n",
      "Epoch [58/60], Train Loss: 0.0000, Val Loss: 0.1750, Val Accuracy: 0.9789, Epoch Time: 2.78s\n",
      "Epoch [59/60], Train Loss: 0.0000, Val Loss: 0.1751, Val Accuracy: 0.9790, Epoch Time: 2.74s\n",
      "Epoch [60/60], Train Loss: 0.0000, Val Loss: 0.1751, Val Accuracy: 0.9790, Epoch Time: 2.80s\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx4awOGAsqt_"
   },
   "source": [
    "## Test model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce4eePUYnI7P",
    "outputId": "37bd10a9-e6e4-4326-e8cc-004c4468f3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at /dt/yisroel/Users/Data_Memorization/song_memorization/LSB/mnist/best_model.pth\n",
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the path to the saved model\n",
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/LSB/mnist\"\n",
    "model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "\n",
    "# Instantiate the model (make sure the model architecture is defined in a previous cell)\n",
    "# Assuming 'model' is already defined and is an instance of your ViT class\n",
    "# model = VisionTransformer(...) # If not already defined, define it here with the correct parameters\n",
    "\n",
    "# Load the saved state dictionary\n",
    "if os.path.exists(model_save_path):\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    print(f\"Model loaded successfully from {model_save_path}\")\n",
    "else:\n",
    "    print(f\"No model found at {model_save_path}\")\n",
    "\n",
    "# Move the model to the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ki4NlOIonIgl"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "def test_model(model, testloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            loss, correct, total = evaluate_batch(images, labels, model, criterion, device)\n",
    "            test_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += total\n",
    "\n",
    "    # Calculate average test loss and accuracy\n",
    "    average_test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyNO4iHariL1"
   },
   "source": [
    "## LSB encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SeNE_Gv0shW_"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.robust_lsb_encoding import (build_tail_payload_from_dataset,\n",
    "                                                            model_capacity_last_byte,\n",
    "                                                            embed_bytes_into_model_last_byte,\n",
    "                                                            extract_all_bytes_from_model_last_byte,\n",
    "                                                            forgiving_tail_parse_from_end)\n",
    "\n",
    "from song_code_reproduction.src.pruning import prune_model_global_l1\n",
    "\n",
    "from song_code_reproduction.src.ssim_eval import ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RQHEG0G399Lx"
   },
   "outputs": [],
   "source": [
    "def calc_ssim(memorization_size, recovered_imgs, memorization_set):\n",
    "  ssim_scores = []\n",
    "  for i in range(memorization_size):\n",
    "    with torch.no_grad():\n",
    "      ext_img = torch.tensor(recovered_imgs[i]).permute(2, 0, 1).unsqueeze(0).float()\n",
    "      src_img = torch.tensor(memorization_set[i][0]).permute(2, 0, 1).unsqueeze(0).float()\n",
    "      ssim_score = 0.5*(1+ssim(ext_img, src_img))\n",
    "      ssim_scores.append(ssim_score)\n",
    "  ssim_scores = torch.tensor(ssim_scores)\n",
    "  return ssim_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEn_5tiNhvEQ",
    "outputId": "7ddb0d36-dd7b-4212-9241-8a267dae821f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 100 images (no pruning)\n",
      "SSIM before pruning:  1.0\n",
      "Test Loss: 0.1642, Test Accuracy: 0.9789\n",
      "Recovered after pruning: 100\n",
      "SSIM After pruning:  0.7124541401863098\n",
      "Test Loss: 0.1627, Test Accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "# 1) Build payload\n",
    "payload, metas = build_tail_payload_from_dataset(memorization_set, max_images=memorization_size)\n",
    "\n",
    "# 2) Embed AT THE END\n",
    "cap = model_capacity_last_byte(model)\n",
    "if len(payload) > cap: raise RuntimeError(f\"Payload {len(payload)} > cap {cap}\")\n",
    "_ = embed_bytes_into_model_last_byte(model, payload, from_end=True)\n",
    "\n",
    "# 3) Immediate round-trip sanity (no pruning)\n",
    "rb_all = extract_all_bytes_from_model_last_byte(model)\n",
    "assert rb_all[-len(payload):] == payload, \"Tail embed mismatch (should never happen without pruning)\"\n",
    "\n",
    "# 4) Decode from END\n",
    "imgs = forgiving_tail_parse_from_end(rb_all, metas)\n",
    "print(\"Recovered\", len(imgs), \"images (no pruning)\")\n",
    "\n",
    "print(\"SSIM before pruning: \", calc_ssim(memorization_size=memorization_size, recovered_imgs=imgs,\n",
    "                memorization_set=memorization_set).item())\n",
    "test_model(model, testloader, device)\n",
    "\n",
    "# ---- prune the model here ----\n",
    "pruned_model = prune_model_global_l1(model, 0.2)\n",
    "\n",
    "# 5) After pruning, decode from END again (works even if bytes flipped/zeroed)\n",
    "rb_all_after = extract_all_bytes_from_model_last_byte(pruned_model)\n",
    "imgs_after = forgiving_tail_parse_from_end(rb_all_after, metas)\n",
    "print(\"Recovered after pruning:\", len(imgs_after))\n",
    "print(\"SSIM After pruning: \", calc_ssim(memorization_size=memorization_size, recovered_imgs=imgs_after,\n",
    "                memorization_set=memorization_set).item())\n",
    "test_model(pruned_model, testloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeWS5y46tO-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-In0VOsBy-yE",
    "outputId": "1d5c66b2-c2e5-442a-99b0-bd31a810e1cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX3iP0J8mXte"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
