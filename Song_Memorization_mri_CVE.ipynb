{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oyDhcmIBaaHB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import albumentations as A  # Image augmentations\n",
    "\n",
    "\n",
    "from mri_dataset import get_mri_datasets\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QAWX2eoL2kvp"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.mri_vit import ViT_Encoder_Decoder\n",
    "\n",
    "from song_code_reproduction.src.org_cve_loss import CVELoss, reconstruct_from_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JfmFbzz6ja81"
   },
   "outputs": [],
   "source": [
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/CVE/mri/\"\n",
    "\n",
    "memorization_size = 100\n",
    "\n",
    "# Training Params\n",
    "BATCH_SIZE = 16\n",
    "num_epochs = 600 # Example number of epochs\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y853H_UcbQSo",
    "outputId": "e7158f27-e3a3-4e5e-8dbb-255e5d314c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n",
      "Number of images in training set: 3182\n",
      "Number of images in validation set: 393\n",
      "Number of images in test set: 354\n",
      "Number of images in memorization set: 100\n"
     ]
    }
   ],
   "source": [
    "mem_transform = A.Compose([\n",
    "                            A.Resize(width=128, height=128, p=1.0),\n",
    "])\n",
    "\n",
    "mem_train_dataset, train_dataset, val_dataset, test_dataset = get_mri_datasets(root_path='mri_data/',\n",
    "                                                                              mem_train_transform_obj=mem_transform)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, \n",
    "                      BATCH_SIZE, \n",
    "                      shuffle=True, \n",
    "                      num_workers=6,  \n",
    "                      pin_memory=True)  \n",
    "valloader = DataLoader(val_dataset, \n",
    "                    BATCH_SIZE,   \n",
    "                    num_workers=6, \n",
    "                    pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(test_dataset, \n",
    "                    BATCH_SIZE,   \n",
    "                    num_workers=6, \n",
    "                    pin_memory=True)\n",
    "\n",
    "mem_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "if memorization_size > len(mem_train_dataset):\n",
    "    memorization_size = len(mem_train_dataset)\n",
    "memorization_indices = torch.randperm(len(mem_train_dataset))[:memorization_size]\n",
    "memorization_set = Subset(mem_train_dataset, memorization_indices.tolist())\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "print(f\"Number of images in training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of images in test set: {len(test_dataset)}\")\n",
    "print(f\"Number of images in memorization set: {memorization_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, torch.Size([3, 128, 128]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memorization_set), memorization_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "udoiZLHFeET8"
   },
   "outputs": [],
   "source": [
    "model = ViT_Encoder_Decoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xbqv9LacHj4",
    "outputId": "56e3bb5b-1a90-47c6-a284-e9cb4f7c6b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hyperparameters and objects defined.\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 600\n",
      "Loss Function: function\n",
      "Optimizer Type: AdamW\n",
      "Scheduler Type: CosineAnnealingLR\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cve_loss = CVELoss(model=model,\n",
    "                   dataset=memorization_set,\n",
    "                   K=memorization_size*3*128*128,\n",
    "                   device=device,)\n",
    "\n",
    "\n",
    "def dice_coef_metric(pred, label):\n",
    "    intersection = 2.0 * (pred * label).sum()\n",
    "    union = pred.sum() + label.sum()\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1.\n",
    "    return intersection / union\n",
    "\n",
    "# Function to calculate the Dice coefficient loss between prediction and ground truth.\n",
    "def dice_coef_loss(pred, label):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * (pred * label).sum() + smooth\n",
    "    union = pred.sum() + label.sum() + smooth\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "# Function to calculate the combined BCE (Binary Cross Entropy) and Dice loss.\n",
    "\n",
    "def bce_dice_loss(pred, label):\n",
    "    pred = torch.sigmoid(pred) \n",
    "    dice_loss = dice_coef_loss(pred, label)\n",
    "    bce_loss = nn.BCELoss()(pred, label)\n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "criterion = lambda pred, label : bce_dice_loss(pred, label) + 1.5*cve_loss()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr= LEARNING_RATE)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(\"Training hyperparameters and objects defined.\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")\n",
    "print(f\"Optimizer Type: {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler Type: {type(scheduler).__name__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HTtpo-aXe_UL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_batch(images, mask, model, criterion, device):\n",
    "    images, mask = images.to(device), mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, mask)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "\n",
    "    return loss.item(), dice, mask.size(0)\n",
    "\n",
    "def main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path):\n",
    "    best_val_dice = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion, device)\n",
    "            running_loss += loss\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        dice_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in valloader:\n",
    "            loss, dice, _ = evaluate_batch(images, labels, model, criterion, device)\n",
    "            val_loss += loss\n",
    "            dice_predictions += dice\n",
    "            total_predictions += 1\n",
    "\n",
    "        epoch_val_loss = val_loss / len(valloader)\n",
    "        dice = dice_predictions / total_predictions\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, '\n",
    "              f'Val Dice: {dice:.4f}, '\n",
    "              f'Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save the best model\n",
    "        if dice > best_val_dice:\n",
    "            best_val_dice = dice\n",
    "            model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model to {model_save_path} with validation DICE: {best_val_dice:.4f}\")\n",
    "\n",
    "\n",
    "        model.train() # Set model back to training mode\n",
    "\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uguhGoO_fo7g"
   },
   "outputs": [],
   "source": [
    "# main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx4awOGAsqt_"
   },
   "source": [
    "## Test model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce4eePUYnI7P",
    "outputId": "37bd10a9-e6e4-4326-e8cc-004c4468f3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /dt/yisroel/Users/Data_Memorization/song_memorization/CVE/mri/best_model.pth\n",
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the path to the saved model\n",
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/CVE/mri/\"\n",
    "model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "\n",
    "# Instantiate the model (make sure the model architecture is defined in a previous cell)\n",
    "# Assuming 'model' is already defined and is an instance of your ViT class\n",
    "# model = VisionTransformer(...) # If not already defined, define it here with the correct parameters\n",
    "\n",
    "# Load the saved state dictionary\n",
    "if os.path.exists(model_save_path):\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    print(f\"Model loaded successfully from {model_save_path}\")\n",
    "else:\n",
    "    print(f\"No model found at {model_save_path}\")\n",
    "\n",
    "# Move the model to the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ki4NlOIonIgl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(model, testloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            loss, correct, _ = evaluate_batch(images, labels, model, criterion, device)\n",
    "            test_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += 1\n",
    "\n",
    "    # Calculate average test loss and accuracy\n",
    "    average_test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test DICE: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyNO4iHariL1"
   },
   "source": [
    "## CVE encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SeNE_Gv0shW_"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.ssim_eval import ssim\n",
    "from song_code_reproduction.src.pruning import prune_model_global_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RQHEG0G399Lx"
   },
   "outputs": [],
   "source": [
    "def calc_ssim(memorization_size, memorization_set, recon):\n",
    "  ssim_scores = []\n",
    "  for i in range(memorization_size):\n",
    "    with torch.no_grad():\n",
    "      ext_img = recon[i].unsqueeze(0)\n",
    "      src_img = memorization_set[i][0].unsqueeze(0)\n",
    "      ssim_score_org = 0.5*(ssim(src_img,ext_img)+1)\n",
    "      ssim_score_inv = 0.5*(ssim(src_img, 1-ext_img)+1)\n",
    "      ssim_score = max(ssim_score_org, ssim_score_inv)\n",
    "      ssim_scores.append(ssim_score)\n",
    "  ssim_scores = torch.tensor(ssim_scores)\n",
    "  return ssim_scores.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEn_5tiNhvEQ",
    "outputId": "7ddb0d36-dd7b-4212-9241-8a267dae821f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM before pruning: 0.5872811675071716\n",
      "Test Loss: -1.1380, Test DICE: 0.8690\n",
      "SSIM after pruning: 0.5786737203598022\n",
      "Test Loss: -1.1377, Test DICE: 0.8688\n"
     ]
    }
   ],
   "source": [
    "recon = reconstruct_from_params(model=model,\n",
    "                                K=100*3*128*128,\n",
    "                                item_shape=(3,128,128),\n",
    "                                value_range=(0.,1.))\n",
    "ssim_before = calc_ssim(memorization_size=memorization_size, memorization_set=memorization_set, recon=recon)\n",
    "print(f\"SSIM before pruning: {ssim_before}\")\n",
    "test_model(model, testloader, device)\n",
    "\n",
    "pruned_model = prune_model_global_l1(model, 0.2)\n",
    "\n",
    "recon = reconstruct_from_params(model=pruned_model,\n",
    "                                K=100*3*128*128,\n",
    "                                item_shape=(3,128,128),\n",
    "                                value_range=(0.,1.))\n",
    "ssim_after = calc_ssim(memorization_size=memorization_size, memorization_set=memorization_set, recon=recon)\n",
    "print(f\"SSIM after pruning: {ssim_after}\")\n",
    "test_model(pruned_model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeWS5y46tO-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-In0VOsBy-yE",
    "outputId": "1d5c66b2-c2e5-442a-99b0-bd31a810e1cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX3iP0J8mXte"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
