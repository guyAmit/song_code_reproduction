{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oyDhcmIBaaHB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import albumentations as A  # Image augmentations\n",
    "\n",
    "\n",
    "from mri_dataset import get_mri_datasets\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QAWX2eoL2kvp"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.mri_vit import ViT_Encoder_Decoder\n",
    "\n",
    "from song_code_reproduction.src.sign_encoding_loss import (\n",
    "    SignEncodingPenalty,\n",
    "    select_all_params,\n",
    "    bytes_to_images_torch,\n",
    "    capacity_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JfmFbzz6ja81"
   },
   "outputs": [],
   "source": [
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/\"\n",
    "\n",
    "memorization_size = 10\n",
    "\n",
    "# Training Params\n",
    "BATCH_SIZE = 16\n",
    "num_epochs = 600 # Example number of epochs\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y853H_UcbQSo",
    "outputId": "e7158f27-e3a3-4e5e-8dbb-255e5d314c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n",
      "Number of images in training set: 3182\n",
      "Number of images in validation set: 393\n",
      "Number of images in test set: 354\n",
      "Number of images in memorization set: 100\n"
     ]
    }
   ],
   "source": [
    "mem_transform = A.Compose([\n",
    "                            A.Resize(width=128, height=128, p=1.0),\n",
    "])\n",
    "\n",
    "mem_train_dataset, train_dataset, val_dataset, test_dataset = get_mri_datasets(root_path='mri_data/',mem_train_transform_obj=mem_transform)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, \n",
    "                      BATCH_SIZE, \n",
    "                      shuffle=True, \n",
    "                      num_workers=6,  \n",
    "                      pin_memory=True)  \n",
    "valloader = DataLoader(val_dataset, \n",
    "                    BATCH_SIZE,   \n",
    "                    num_workers=6, \n",
    "                    pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(test_dataset, \n",
    "                    BATCH_SIZE,   \n",
    "                    num_workers=6, \n",
    "                    pin_memory=True)\n",
    "\n",
    "if memorization_size > len(mem_train_dataset):\n",
    "    memorization_size = len(mem_train_dataset)\n",
    "memorization_indices = torch.randperm(len(mem_train_dataset))[:memorization_size].tolist()\n",
    "memorization_set = Subset(mem_train_dataset, memorization_indices)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "print(f\"Number of images in training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of images in test set: {len(test_dataset)}\")\n",
    "print(f\"Number of images in memorization set: {memorization_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, torch.Size([3, 128, 128]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memorization_set), memorization_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "udoiZLHFeET8"
   },
   "outputs": [],
   "source": [
    "model = ViT_Encoder_Decoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xbqv9LacHj4",
    "outputId": "56e3bb5b-1a90-47c6-a284-e9cb4f7c6b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity: subset L=21698176, redundancy k=5, available bits B=4339635, fits ~11 images\n",
      "Training hyperparameters and objects defined.\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 600\n",
      "Loss Function: function\n",
      "Optimizer Type: AdamW\n",
      "Scheduler Type: CosineAnnealingLR\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "sign_penalty = SignEncodingPenalty(\n",
    "    model=model,\n",
    "    dataset=memorization_set,\n",
    "    subset_selector=select_all_params,\n",
    "    lambda_max=50.0,\n",
    "    margin=1e-3,\n",
    "    redundancy_k=5,         # IMPORTANT: maximize capacity for visible recon\n",
    "    device=device,\n",
    "    float_mode=\"clip01\",\n",
    ")\n",
    "\n",
    "print(capacity_report(sign_penalty, bits_per_image=3*128*128*8))\n",
    "\n",
    "def dice_coef_metric(pred, label):\n",
    "    intersection = 2.0 * (pred * label).sum()\n",
    "    union = pred.sum() + label.sum()\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1.\n",
    "    return intersection / union\n",
    "\n",
    "# Function to calculate the Dice coefficient loss between prediction and ground truth.\n",
    "def dice_coef_loss(pred, label):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * (pred * label).sum() + smooth\n",
    "    union = pred.sum() + label.sum() + smooth\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "# Function to calculate the combined BCE (Binary Cross Entropy) and Dice loss.\n",
    "\n",
    "def bce_dice_loss(pred, label):\n",
    "    pred = torch.sigmoid(pred) \n",
    "    dice_loss = dice_coef_loss(pred, label)\n",
    "    bce_loss = nn.BCELoss()(pred, label)\n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "criterion = bce_dice_loss\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr= LEARNING_RATE, weight_decay=0)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(\"Training hyperparameters and objects defined.\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")\n",
    "print(f\"Optimizer Type: {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler Type: {type(scheduler).__name__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HTtpo-aXe_UL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, step, total_steps, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels) + sign_penalty(step, total_steps)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_batch(images, mask, model, criterion, device):\n",
    "    images, mask = images.to(device), mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, mask)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "\n",
    "    return loss.item(), dice, mask.size(0)\n",
    "\n",
    "def main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path):\n",
    "    best_train_loss = float('inf')\n",
    "    \n",
    "    total_steps = num_epochs * len(trainloader)\n",
    "    step = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        # Training phase\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion, step, total_steps, device)\n",
    "            running_loss += loss\n",
    "            step += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        dice_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in valloader:\n",
    "            loss, dice, _ = evaluate_batch(images, labels, model, criterion, device)\n",
    "            val_loss += loss\n",
    "            dice_predictions += dice\n",
    "            total_predictions += 1\n",
    "\n",
    "        epoch_val_loss = val_loss / len(valloader)\n",
    "        dice = dice_predictions / total_predictions\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, '\n",
    "              f'Val Dice: {dice:.4f}, '\n",
    "              f'Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save the best model based on training loss\n",
    "        if epoch_loss < best_train_loss:\n",
    "            best_train_loss = epoch_loss\n",
    "            model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model to {model_save_path} with training loss: {best_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "        model.train() # Set model back to training mode\n",
    "        model_save_path = os.path.join(save_path, 'last_model.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uguhGoO_fo7g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/600], Train Loss: 0.8311, Val Loss: 0.6575, Val Dice: 0.4060, Epoch Time: 7.55s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.8311\n",
      "Epoch [2/600], Train Loss: 0.6478, Val Loss: 0.6023, Val Dice: 0.4684, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.6478\n",
      "Epoch [3/600], Train Loss: 0.6287, Val Loss: 0.5651, Val Dice: 0.4981, Epoch Time: 5.89s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.6287\n",
      "Epoch [4/600], Train Loss: 0.5531, Val Loss: 0.4772, Val Dice: 0.5818, Epoch Time: 6.04s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.5531\n",
      "Epoch [5/600], Train Loss: 0.5456, Val Loss: 0.4587, Val Dice: 0.5960, Epoch Time: 5.93s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.5456\n",
      "Epoch [6/600], Train Loss: 0.4972, Val Loss: 0.4660, Val Dice: 0.5795, Epoch Time: 5.97s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4972\n",
      "Epoch [7/600], Train Loss: 0.4723, Val Loss: 0.4186, Val Dice: 0.6320, Epoch Time: 5.91s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4723\n",
      "Epoch [8/600], Train Loss: 0.4562, Val Loss: 0.4166, Val Dice: 0.6252, Epoch Time: 6.06s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4562\n",
      "Epoch [9/600], Train Loss: 0.4410, Val Loss: 0.4230, Val Dice: 0.6249, Epoch Time: 5.81s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4410\n",
      "Epoch [10/600], Train Loss: 0.4612, Val Loss: 0.4209, Val Dice: 0.6384, Epoch Time: 5.76s\n",
      "Epoch [11/600], Train Loss: 0.4563, Val Loss: 0.4014, Val Dice: 0.6388, Epoch Time: 6.15s\n",
      "Epoch [12/600], Train Loss: 0.4276, Val Loss: 0.3694, Val Dice: 0.6779, Epoch Time: 6.13s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4276\n",
      "Epoch [13/600], Train Loss: 0.4192, Val Loss: 0.3910, Val Dice: 0.6645, Epoch Time: 6.14s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4192\n",
      "Epoch [14/600], Train Loss: 0.4133, Val Loss: 0.4076, Val Dice: 0.6380, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4133\n",
      "Epoch [15/600], Train Loss: 0.4124, Val Loss: 0.3805, Val Dice: 0.6532, Epoch Time: 5.81s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4124\n",
      "Epoch [16/600], Train Loss: 0.4132, Val Loss: 0.3836, Val Dice: 0.6537, Epoch Time: 6.17s\n",
      "Epoch [17/600], Train Loss: 0.4230, Val Loss: 0.3816, Val Dice: 0.6666, Epoch Time: 6.17s\n",
      "Epoch [18/600], Train Loss: 0.4344, Val Loss: 0.3629, Val Dice: 0.6766, Epoch Time: 6.13s\n",
      "Epoch [19/600], Train Loss: 0.4129, Val Loss: 0.3808, Val Dice: 0.6730, Epoch Time: 6.22s\n",
      "Epoch [20/600], Train Loss: 0.4093, Val Loss: 0.3716, Val Dice: 0.6778, Epoch Time: 5.88s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4093\n",
      "Epoch [21/600], Train Loss: 0.4015, Val Loss: 0.3317, Val Dice: 0.7112, Epoch Time: 5.76s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.4015\n",
      "Epoch [22/600], Train Loss: 0.3970, Val Loss: 0.3361, Val Dice: 0.7096, Epoch Time: 6.00s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3970\n",
      "Epoch [23/600], Train Loss: 0.3999, Val Loss: 0.3302, Val Dice: 0.7033, Epoch Time: 5.83s\n",
      "Epoch [24/600], Train Loss: 0.4250, Val Loss: 0.3505, Val Dice: 0.6963, Epoch Time: 6.24s\n",
      "Epoch [25/600], Train Loss: 0.4100, Val Loss: 0.3500, Val Dice: 0.6960, Epoch Time: 6.10s\n",
      "Epoch [26/600], Train Loss: 0.4045, Val Loss: 0.3206, Val Dice: 0.7100, Epoch Time: 6.24s\n",
      "Epoch [27/600], Train Loss: 0.3803, Val Loss: 0.3236, Val Dice: 0.7129, Epoch Time: 6.11s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3803\n",
      "Epoch [28/600], Train Loss: 0.3880, Val Loss: 0.3518, Val Dice: 0.6795, Epoch Time: 6.10s\n",
      "Epoch [29/600], Train Loss: 0.3824, Val Loss: 0.3279, Val Dice: 0.7086, Epoch Time: 5.76s\n",
      "Epoch [30/600], Train Loss: 0.3954, Val Loss: 0.3393, Val Dice: 0.7053, Epoch Time: 6.16s\n",
      "Epoch [31/600], Train Loss: 0.3745, Val Loss: 0.3152, Val Dice: 0.7266, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3745\n",
      "Epoch [32/600], Train Loss: 0.3890, Val Loss: 0.3750, Val Dice: 0.6649, Epoch Time: 6.05s\n",
      "Epoch [33/600], Train Loss: 0.3857, Val Loss: 0.3092, Val Dice: 0.7214, Epoch Time: 6.07s\n",
      "Epoch [34/600], Train Loss: 0.3622, Val Loss: 0.2968, Val Dice: 0.7445, Epoch Time: 6.25s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3622\n",
      "Epoch [35/600], Train Loss: 0.3780, Val Loss: 0.3340, Val Dice: 0.7006, Epoch Time: 6.10s\n",
      "Epoch [36/600], Train Loss: 0.3868, Val Loss: 0.3028, Val Dice: 0.7306, Epoch Time: 6.08s\n",
      "Epoch [37/600], Train Loss: 0.3737, Val Loss: 0.3383, Val Dice: 0.6948, Epoch Time: 6.02s\n",
      "Epoch [38/600], Train Loss: 0.3990, Val Loss: 0.3107, Val Dice: 0.7291, Epoch Time: 5.98s\n",
      "Epoch [39/600], Train Loss: 0.3754, Val Loss: 0.2882, Val Dice: 0.7472, Epoch Time: 5.93s\n",
      "Epoch [40/600], Train Loss: 0.3612, Val Loss: 0.2892, Val Dice: 0.7452, Epoch Time: 6.09s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3612\n",
      "Epoch [41/600], Train Loss: 0.3615, Val Loss: 0.3327, Val Dice: 0.6980, Epoch Time: 6.09s\n",
      "Epoch [42/600], Train Loss: 0.3507, Val Loss: 0.2714, Val Dice: 0.7647, Epoch Time: 5.99s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3507\n",
      "Epoch [43/600], Train Loss: 0.3501, Val Loss: 0.3262, Val Dice: 0.7184, Epoch Time: 5.92s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3501\n",
      "Epoch [44/600], Train Loss: 0.3708, Val Loss: 0.2841, Val Dice: 0.7486, Epoch Time: 6.28s\n",
      "Epoch [45/600], Train Loss: 0.3465, Val Loss: 0.2794, Val Dice: 0.7552, Epoch Time: 6.16s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3465\n",
      "Epoch [46/600], Train Loss: 0.3595, Val Loss: 0.3035, Val Dice: 0.7336, Epoch Time: 5.96s\n",
      "Epoch [47/600], Train Loss: 0.3575, Val Loss: 0.2818, Val Dice: 0.7516, Epoch Time: 6.15s\n",
      "Epoch [48/600], Train Loss: 0.3508, Val Loss: 0.2693, Val Dice: 0.7610, Epoch Time: 6.24s\n",
      "Epoch [49/600], Train Loss: 0.3498, Val Loss: 0.2865, Val Dice: 0.7405, Epoch Time: 6.12s\n",
      "Epoch [50/600], Train Loss: 0.3481, Val Loss: 0.2707, Val Dice: 0.7623, Epoch Time: 6.03s\n",
      "Epoch [51/600], Train Loss: 0.3490, Val Loss: 0.2867, Val Dice: 0.7451, Epoch Time: 6.06s\n",
      "Epoch [52/600], Train Loss: 0.3506, Val Loss: 0.2582, Val Dice: 0.7765, Epoch Time: 6.01s\n",
      "Epoch [53/600], Train Loss: 0.3481, Val Loss: 0.2857, Val Dice: 0.7516, Epoch Time: 6.09s\n",
      "Epoch [54/600], Train Loss: 0.3384, Val Loss: 0.2773, Val Dice: 0.7594, Epoch Time: 6.10s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3384\n",
      "Epoch [55/600], Train Loss: 0.3381, Val Loss: 0.2765, Val Dice: 0.7537, Epoch Time: 6.15s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3381\n",
      "Epoch [56/600], Train Loss: 0.3239, Val Loss: 0.2518, Val Dice: 0.7751, Epoch Time: 6.41s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3239\n",
      "Epoch [57/600], Train Loss: 0.3373, Val Loss: 0.2635, Val Dice: 0.7742, Epoch Time: 5.92s\n",
      "Epoch [58/600], Train Loss: 0.3459, Val Loss: 0.2563, Val Dice: 0.7724, Epoch Time: 6.09s\n",
      "Epoch [59/600], Train Loss: 0.3281, Val Loss: 0.2628, Val Dice: 0.7667, Epoch Time: 6.07s\n",
      "Epoch [60/600], Train Loss: 0.3314, Val Loss: 0.2510, Val Dice: 0.7815, Epoch Time: 6.06s\n",
      "Epoch [61/600], Train Loss: 0.3358, Val Loss: 0.2680, Val Dice: 0.7667, Epoch Time: 5.98s\n",
      "Epoch [62/600], Train Loss: 0.3031, Val Loss: 0.2399, Val Dice: 0.7894, Epoch Time: 5.98s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.3031\n",
      "Epoch [63/600], Train Loss: 0.3379, Val Loss: 0.3692, Val Dice: 0.6879, Epoch Time: 6.03s\n",
      "Epoch [64/600], Train Loss: 0.3383, Val Loss: 0.2667, Val Dice: 0.7678, Epoch Time: 6.32s\n",
      "Epoch [65/600], Train Loss: 0.3205, Val Loss: 0.2336, Val Dice: 0.7960, Epoch Time: 5.82s\n",
      "Epoch [66/600], Train Loss: 0.2997, Val Loss: 0.2501, Val Dice: 0.7808, Epoch Time: 6.10s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2997\n",
      "Epoch [67/600], Train Loss: 0.3405, Val Loss: 0.2362, Val Dice: 0.7951, Epoch Time: 5.83s\n",
      "Epoch [68/600], Train Loss: 0.3095, Val Loss: 0.2316, Val Dice: 0.7950, Epoch Time: 5.86s\n",
      "Epoch [69/600], Train Loss: 0.3143, Val Loss: 0.2335, Val Dice: 0.7915, Epoch Time: 5.88s\n",
      "Epoch [70/600], Train Loss: 0.3173, Val Loss: 0.2395, Val Dice: 0.7878, Epoch Time: 5.91s\n",
      "Epoch [71/600], Train Loss: 0.3054, Val Loss: 0.2349, Val Dice: 0.7919, Epoch Time: 6.26s\n",
      "Epoch [72/600], Train Loss: 0.3152, Val Loss: 0.2425, Val Dice: 0.7817, Epoch Time: 6.23s\n",
      "Epoch [73/600], Train Loss: 0.3020, Val Loss: 0.2330, Val Dice: 0.7953, Epoch Time: 6.12s\n",
      "Epoch [74/600], Train Loss: 0.3042, Val Loss: 0.2267, Val Dice: 0.7987, Epoch Time: 6.16s\n",
      "Epoch [75/600], Train Loss: 0.2887, Val Loss: 0.2322, Val Dice: 0.7986, Epoch Time: 5.94s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2887\n",
      "Epoch [76/600], Train Loss: 0.3003, Val Loss: 0.2363, Val Dice: 0.7894, Epoch Time: 5.98s\n",
      "Epoch [77/600], Train Loss: 0.3089, Val Loss: 0.2340, Val Dice: 0.7925, Epoch Time: 6.12s\n",
      "Epoch [78/600], Train Loss: 0.3142, Val Loss: 0.2363, Val Dice: 0.7942, Epoch Time: 6.10s\n",
      "Epoch [79/600], Train Loss: 0.2998, Val Loss: 0.2202, Val Dice: 0.8053, Epoch Time: 6.08s\n",
      "Epoch [80/600], Train Loss: 0.3019, Val Loss: 0.2184, Val Dice: 0.8070, Epoch Time: 6.03s\n",
      "Epoch [81/600], Train Loss: 0.3165, Val Loss: 0.2219, Val Dice: 0.8070, Epoch Time: 5.91s\n",
      "Epoch [82/600], Train Loss: 0.2880, Val Loss: 0.2222, Val Dice: 0.8047, Epoch Time: 6.04s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2880\n",
      "Epoch [83/600], Train Loss: 0.3322, Val Loss: 0.2795, Val Dice: 0.7506, Epoch Time: 5.83s\n",
      "Epoch [84/600], Train Loss: 0.3256, Val Loss: 0.2296, Val Dice: 0.7991, Epoch Time: 6.00s\n",
      "Epoch [85/600], Train Loss: 0.2984, Val Loss: 0.2180, Val Dice: 0.8066, Epoch Time: 5.91s\n",
      "Epoch [86/600], Train Loss: 0.2999, Val Loss: 0.2311, Val Dice: 0.8022, Epoch Time: 6.19s\n",
      "Epoch [87/600], Train Loss: 0.2932, Val Loss: 0.2201, Val Dice: 0.8038, Epoch Time: 5.91s\n",
      "Epoch [88/600], Train Loss: 0.2849, Val Loss: 0.2175, Val Dice: 0.8079, Epoch Time: 6.11s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2849\n",
      "Epoch [89/600], Train Loss: 0.2850, Val Loss: 0.2222, Val Dice: 0.8057, Epoch Time: 6.03s\n",
      "Epoch [90/600], Train Loss: 0.2802, Val Loss: 0.2111, Val Dice: 0.8141, Epoch Time: 6.02s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2802\n",
      "Epoch [91/600], Train Loss: 0.2838, Val Loss: 0.2273, Val Dice: 0.7990, Epoch Time: 6.08s\n",
      "Epoch [92/600], Train Loss: 0.2964, Val Loss: 0.2193, Val Dice: 0.8099, Epoch Time: 6.10s\n",
      "Epoch [93/600], Train Loss: 0.2842, Val Loss: 0.2382, Val Dice: 0.7861, Epoch Time: 6.18s\n",
      "Epoch [94/600], Train Loss: 0.2808, Val Loss: 0.2164, Val Dice: 0.8084, Epoch Time: 6.17s\n",
      "Epoch [95/600], Train Loss: 0.2764, Val Loss: 0.2394, Val Dice: 0.7822, Epoch Time: 6.25s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2764\n",
      "Epoch [96/600], Train Loss: 0.2697, Val Loss: 0.2204, Val Dice: 0.8015, Epoch Time: 6.05s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2697\n",
      "Epoch [97/600], Train Loss: 0.2811, Val Loss: 0.2064, Val Dice: 0.8211, Epoch Time: 5.98s\n",
      "Epoch [98/600], Train Loss: 0.2764, Val Loss: 0.2041, Val Dice: 0.8187, Epoch Time: 6.03s\n",
      "Epoch [99/600], Train Loss: 0.2684, Val Loss: 0.2042, Val Dice: 0.8180, Epoch Time: 6.07s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2684\n",
      "Epoch [100/600], Train Loss: 0.2789, Val Loss: 0.2162, Val Dice: 0.8053, Epoch Time: 6.20s\n",
      "Epoch [101/600], Train Loss: 0.2874, Val Loss: 0.2458, Val Dice: 0.7839, Epoch Time: 5.99s\n",
      "Epoch [102/600], Train Loss: 0.3086, Val Loss: 0.2101, Val Dice: 0.8130, Epoch Time: 5.88s\n",
      "Epoch [103/600], Train Loss: 0.2710, Val Loss: 0.1982, Val Dice: 0.8279, Epoch Time: 6.22s\n",
      "Epoch [104/600], Train Loss: 0.2909, Val Loss: 0.2204, Val Dice: 0.8015, Epoch Time: 6.08s\n",
      "Epoch [105/600], Train Loss: 0.2915, Val Loss: 0.2180, Val Dice: 0.8060, Epoch Time: 6.18s\n",
      "Epoch [106/600], Train Loss: 0.2699, Val Loss: 0.2053, Val Dice: 0.8172, Epoch Time: 5.71s\n",
      "Epoch [107/600], Train Loss: 0.2667, Val Loss: 0.2076, Val Dice: 0.8154, Epoch Time: 5.78s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2667\n",
      "Epoch [108/600], Train Loss: 0.2679, Val Loss: 0.1979, Val Dice: 0.8251, Epoch Time: 6.11s\n",
      "Epoch [109/600], Train Loss: 0.2815, Val Loss: 0.2486, Val Dice: 0.7773, Epoch Time: 5.80s\n",
      "Epoch [110/600], Train Loss: 0.3087, Val Loss: 0.3387, Val Dice: 0.7073, Epoch Time: 6.01s\n",
      "Epoch [111/600], Train Loss: 0.3171, Val Loss: 0.2292, Val Dice: 0.7962, Epoch Time: 5.93s\n",
      "Epoch [112/600], Train Loss: 0.2763, Val Loss: 0.2057, Val Dice: 0.8190, Epoch Time: 6.14s\n",
      "Epoch [113/600], Train Loss: 0.2746, Val Loss: 0.1954, Val Dice: 0.8268, Epoch Time: 5.97s\n",
      "Epoch [114/600], Train Loss: 0.2668, Val Loss: 0.2064, Val Dice: 0.8194, Epoch Time: 5.78s\n",
      "Epoch [115/600], Train Loss: 0.2668, Val Loss: 0.1889, Val Dice: 0.8351, Epoch Time: 6.28s\n",
      "Epoch [116/600], Train Loss: 0.2853, Val Loss: 0.2040, Val Dice: 0.8197, Epoch Time: 5.99s\n",
      "Epoch [117/600], Train Loss: 0.2748, Val Loss: 0.2005, Val Dice: 0.8199, Epoch Time: 5.98s\n",
      "Epoch [118/600], Train Loss: 0.2570, Val Loss: 0.1930, Val Dice: 0.8282, Epoch Time: 5.80s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2570\n",
      "Epoch [119/600], Train Loss: 0.2603, Val Loss: 0.2217, Val Dice: 0.8058, Epoch Time: 6.16s\n",
      "Epoch [120/600], Train Loss: 0.2857, Val Loss: 0.2134, Val Dice: 0.8092, Epoch Time: 6.06s\n",
      "Epoch [121/600], Train Loss: 0.2739, Val Loss: 0.1954, Val Dice: 0.8286, Epoch Time: 6.07s\n",
      "Epoch [122/600], Train Loss: 0.2734, Val Loss: 0.2136, Val Dice: 0.8065, Epoch Time: 5.94s\n",
      "Epoch [123/600], Train Loss: 0.2763, Val Loss: 0.1961, Val Dice: 0.8281, Epoch Time: 5.93s\n",
      "Epoch [124/600], Train Loss: 0.2585, Val Loss: 0.1932, Val Dice: 0.8284, Epoch Time: 5.94s\n",
      "Epoch [125/600], Train Loss: 0.2670, Val Loss: 0.1923, Val Dice: 0.8299, Epoch Time: 6.07s\n",
      "Epoch [126/600], Train Loss: 0.2619, Val Loss: 0.1943, Val Dice: 0.8292, Epoch Time: 6.10s\n",
      "Epoch [127/600], Train Loss: 0.2668, Val Loss: 0.2092, Val Dice: 0.8158, Epoch Time: 6.20s\n",
      "Epoch [128/600], Train Loss: 0.2688, Val Loss: 0.1892, Val Dice: 0.8336, Epoch Time: 6.00s\n",
      "Epoch [129/600], Train Loss: 0.3289, Val Loss: 0.2235, Val Dice: 0.8025, Epoch Time: 5.97s\n",
      "Epoch [130/600], Train Loss: 0.2802, Val Loss: 0.2028, Val Dice: 0.8198, Epoch Time: 6.02s\n",
      "Epoch [131/600], Train Loss: 0.2759, Val Loss: 0.1876, Val Dice: 0.8342, Epoch Time: 6.08s\n",
      "Epoch [132/600], Train Loss: 0.2664, Val Loss: 0.1924, Val Dice: 0.8315, Epoch Time: 6.01s\n",
      "Epoch [133/600], Train Loss: 0.2610, Val Loss: 0.1917, Val Dice: 0.8286, Epoch Time: 6.08s\n",
      "Epoch [134/600], Train Loss: 0.2593, Val Loss: 0.1894, Val Dice: 0.8307, Epoch Time: 6.30s\n",
      "Epoch [135/600], Train Loss: 0.2690, Val Loss: 0.2005, Val Dice: 0.8201, Epoch Time: 5.95s\n",
      "Epoch [136/600], Train Loss: 0.2666, Val Loss: 0.2051, Val Dice: 0.8150, Epoch Time: 6.09s\n",
      "Epoch [137/600], Train Loss: 0.2678, Val Loss: 0.1852, Val Dice: 0.8355, Epoch Time: 6.09s\n",
      "Epoch [138/600], Train Loss: 0.2535, Val Loss: 0.1896, Val Dice: 0.8302, Epoch Time: 5.89s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2535\n",
      "Epoch [139/600], Train Loss: 0.2771, Val Loss: 0.1822, Val Dice: 0.8389, Epoch Time: 5.78s\n",
      "Epoch [140/600], Train Loss: 0.2607, Val Loss: 0.1879, Val Dice: 0.8324, Epoch Time: 5.99s\n",
      "Epoch [141/600], Train Loss: 0.2563, Val Loss: 0.1870, Val Dice: 0.8323, Epoch Time: 6.18s\n",
      "Epoch [142/600], Train Loss: 0.2531, Val Loss: 0.1848, Val Dice: 0.8357, Epoch Time: 5.96s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2531\n",
      "Epoch [143/600], Train Loss: 0.2549, Val Loss: 0.2064, Val Dice: 0.8162, Epoch Time: 6.04s\n",
      "Epoch [144/600], Train Loss: 0.3014, Val Loss: 0.2031, Val Dice: 0.8186, Epoch Time: 5.95s\n",
      "Epoch [145/600], Train Loss: 0.2630, Val Loss: 0.1882, Val Dice: 0.8330, Epoch Time: 5.94s\n",
      "Epoch [146/600], Train Loss: 0.2752, Val Loss: 0.2539, Val Dice: 0.7777, Epoch Time: 6.20s\n",
      "Epoch [147/600], Train Loss: 0.2801, Val Loss: 0.1923, Val Dice: 0.8306, Epoch Time: 6.37s\n",
      "Epoch [148/600], Train Loss: 0.2652, Val Loss: 0.1916, Val Dice: 0.8274, Epoch Time: 6.12s\n",
      "Epoch [149/600], Train Loss: 0.2594, Val Loss: 0.1873, Val Dice: 0.8343, Epoch Time: 5.95s\n",
      "Epoch [150/600], Train Loss: 0.2569, Val Loss: 0.1869, Val Dice: 0.8352, Epoch Time: 6.13s\n",
      "Epoch [151/600], Train Loss: 0.2599, Val Loss: 0.1841, Val Dice: 0.8384, Epoch Time: 6.25s\n",
      "Epoch [152/600], Train Loss: 0.2541, Val Loss: 0.1819, Val Dice: 0.8404, Epoch Time: 6.02s\n",
      "Epoch [153/600], Train Loss: 0.2490, Val Loss: 0.1845, Val Dice: 0.8369, Epoch Time: 6.23s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2490\n",
      "Epoch [154/600], Train Loss: 0.2496, Val Loss: 0.1836, Val Dice: 0.8388, Epoch Time: 6.10s\n",
      "Epoch [155/600], Train Loss: 0.2746, Val Loss: 0.1852, Val Dice: 0.8370, Epoch Time: 5.89s\n",
      "Epoch [156/600], Train Loss: 0.2516, Val Loss: 0.1910, Val Dice: 0.8319, Epoch Time: 6.18s\n",
      "Epoch [157/600], Train Loss: 0.2583, Val Loss: 0.1801, Val Dice: 0.8422, Epoch Time: 6.28s\n",
      "Epoch [158/600], Train Loss: 0.2569, Val Loss: 0.1811, Val Dice: 0.8426, Epoch Time: 5.88s\n",
      "Epoch [159/600], Train Loss: 0.2448, Val Loss: 0.1834, Val Dice: 0.8375, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2448\n",
      "Epoch [160/600], Train Loss: 0.2661, Val Loss: 0.1881, Val Dice: 0.8345, Epoch Time: 6.12s\n",
      "Epoch [161/600], Train Loss: 0.2494, Val Loss: 0.1831, Val Dice: 0.8389, Epoch Time: 5.95s\n",
      "Epoch [162/600], Train Loss: 0.2491, Val Loss: 0.1841, Val Dice: 0.8390, Epoch Time: 5.93s\n",
      "Epoch [163/600], Train Loss: 0.2470, Val Loss: 0.1834, Val Dice: 0.8370, Epoch Time: 6.12s\n",
      "Epoch [164/600], Train Loss: 0.2489, Val Loss: 0.1797, Val Dice: 0.8425, Epoch Time: 6.11s\n",
      "Epoch [165/600], Train Loss: 0.2467, Val Loss: 0.1834, Val Dice: 0.8359, Epoch Time: 5.97s\n",
      "Epoch [166/600], Train Loss: 0.2503, Val Loss: 0.1796, Val Dice: 0.8395, Epoch Time: 6.01s\n",
      "Epoch [167/600], Train Loss: 0.2604, Val Loss: 0.1854, Val Dice: 0.8382, Epoch Time: 5.74s\n",
      "Epoch [168/600], Train Loss: 0.2521, Val Loss: 0.1809, Val Dice: 0.8399, Epoch Time: 6.23s\n",
      "Epoch [169/600], Train Loss: 0.2538, Val Loss: 0.1848, Val Dice: 0.8346, Epoch Time: 5.86s\n",
      "Epoch [170/600], Train Loss: 0.2778, Val Loss: 0.1805, Val Dice: 0.8418, Epoch Time: 5.93s\n",
      "Epoch [171/600], Train Loss: 0.2569, Val Loss: 0.1772, Val Dice: 0.8432, Epoch Time: 5.81s\n",
      "Epoch [172/600], Train Loss: 0.2598, Val Loss: 0.1817, Val Dice: 0.8387, Epoch Time: 6.20s\n",
      "Epoch [173/600], Train Loss: 0.2429, Val Loss: 0.2100, Val Dice: 0.8167, Epoch Time: 6.25s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2429\n",
      "Epoch [174/600], Train Loss: 0.2719, Val Loss: 0.1813, Val Dice: 0.8396, Epoch Time: 6.12s\n",
      "Epoch [175/600], Train Loss: 0.2445, Val Loss: 0.1753, Val Dice: 0.8455, Epoch Time: 5.96s\n",
      "Epoch [176/600], Train Loss: 0.2483, Val Loss: 0.1954, Val Dice: 0.8325, Epoch Time: 6.15s\n",
      "Epoch [177/600], Train Loss: 0.2559, Val Loss: 0.1755, Val Dice: 0.8439, Epoch Time: 5.99s\n",
      "Epoch [178/600], Train Loss: 0.2449, Val Loss: 0.1827, Val Dice: 0.8380, Epoch Time: 5.95s\n",
      "Epoch [179/600], Train Loss: 0.2535, Val Loss: 0.1789, Val Dice: 0.8414, Epoch Time: 5.88s\n",
      "Epoch [180/600], Train Loss: 0.2437, Val Loss: 0.1703, Val Dice: 0.8510, Epoch Time: 6.07s\n",
      "Epoch [181/600], Train Loss: 0.2490, Val Loss: 0.1786, Val Dice: 0.8438, Epoch Time: 6.07s\n",
      "Epoch [182/600], Train Loss: 0.2464, Val Loss: 0.1803, Val Dice: 0.8422, Epoch Time: 5.90s\n",
      "Epoch [183/600], Train Loss: 0.2730, Val Loss: 0.2961, Val Dice: 0.7426, Epoch Time: 6.26s\n",
      "Epoch [184/600], Train Loss: 0.3043, Val Loss: 0.1843, Val Dice: 0.8371, Epoch Time: 6.08s\n",
      "Epoch [185/600], Train Loss: 0.2793, Val Loss: 0.1763, Val Dice: 0.8432, Epoch Time: 6.14s\n",
      "Epoch [186/600], Train Loss: 0.2559, Val Loss: 0.1732, Val Dice: 0.8476, Epoch Time: 6.02s\n",
      "Epoch [187/600], Train Loss: 0.2501, Val Loss: 0.1926, Val Dice: 0.8299, Epoch Time: 6.01s\n",
      "Epoch [188/600], Train Loss: 0.2564, Val Loss: 0.1806, Val Dice: 0.8393, Epoch Time: 6.27s\n",
      "Epoch [189/600], Train Loss: 0.2441, Val Loss: 0.1727, Val Dice: 0.8467, Epoch Time: 6.09s\n",
      "Epoch [190/600], Train Loss: 0.2514, Val Loss: 0.1691, Val Dice: 0.8505, Epoch Time: 5.95s\n",
      "Epoch [191/600], Train Loss: 0.2657, Val Loss: 0.1971, Val Dice: 0.8241, Epoch Time: 6.12s\n",
      "Epoch [192/600], Train Loss: 0.2483, Val Loss: 0.1706, Val Dice: 0.8494, Epoch Time: 6.02s\n",
      "Epoch [193/600], Train Loss: 0.2433, Val Loss: 0.1738, Val Dice: 0.8463, Epoch Time: 6.01s\n",
      "Epoch [194/600], Train Loss: 0.2482, Val Loss: 0.1697, Val Dice: 0.8489, Epoch Time: 6.14s\n",
      "Epoch [195/600], Train Loss: 0.2379, Val Loss: 0.1712, Val Dice: 0.8488, Epoch Time: 6.13s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2379\n",
      "Epoch [196/600], Train Loss: 0.2663, Val Loss: 0.1787, Val Dice: 0.8440, Epoch Time: 5.89s\n",
      "Epoch [197/600], Train Loss: 0.2468, Val Loss: 0.1719, Val Dice: 0.8487, Epoch Time: 5.98s\n",
      "Epoch [198/600], Train Loss: 0.2437, Val Loss: 0.1690, Val Dice: 0.8514, Epoch Time: 6.07s\n",
      "Epoch [199/600], Train Loss: 0.2616, Val Loss: 0.1734, Val Dice: 0.8468, Epoch Time: 5.98s\n",
      "Epoch [200/600], Train Loss: 0.2391, Val Loss: 0.1714, Val Dice: 0.8476, Epoch Time: 5.94s\n",
      "Epoch [201/600], Train Loss: 0.2385, Val Loss: 0.1723, Val Dice: 0.8466, Epoch Time: 5.76s\n",
      "Epoch [202/600], Train Loss: 0.2352, Val Loss: 0.1689, Val Dice: 0.8516, Epoch Time: 5.92s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2352\n",
      "Epoch [203/600], Train Loss: 0.2390, Val Loss: 0.1684, Val Dice: 0.8508, Epoch Time: 6.08s\n",
      "Epoch [204/600], Train Loss: 0.2335, Val Loss: 0.1645, Val Dice: 0.8546, Epoch Time: 6.04s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2335\n",
      "Epoch [205/600], Train Loss: 0.2345, Val Loss: 0.1729, Val Dice: 0.8450, Epoch Time: 6.04s\n",
      "Epoch [206/600], Train Loss: 0.2364, Val Loss: 0.1695, Val Dice: 0.8501, Epoch Time: 5.91s\n",
      "Epoch [207/600], Train Loss: 0.2339, Val Loss: 0.1613, Val Dice: 0.8558, Epoch Time: 6.17s\n",
      "Epoch [208/600], Train Loss: 0.2367, Val Loss: 0.1633, Val Dice: 0.8565, Epoch Time: 6.06s\n",
      "Epoch [209/600], Train Loss: 0.2408, Val Loss: 0.1689, Val Dice: 0.8527, Epoch Time: 6.23s\n",
      "Epoch [210/600], Train Loss: 0.2407, Val Loss: 0.1699, Val Dice: 0.8483, Epoch Time: 5.93s\n",
      "Epoch [211/600], Train Loss: 0.2331, Val Loss: 0.1690, Val Dice: 0.8523, Epoch Time: 6.02s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2331\n",
      "Epoch [212/600], Train Loss: 0.2453, Val Loss: 0.1647, Val Dice: 0.8525, Epoch Time: 6.18s\n",
      "Epoch [213/600], Train Loss: 0.2318, Val Loss: 0.1634, Val Dice: 0.8555, Epoch Time: 6.09s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2318\n",
      "Epoch [214/600], Train Loss: 0.2345, Val Loss: 0.1676, Val Dice: 0.8493, Epoch Time: 6.17s\n",
      "Epoch [215/600], Train Loss: 0.2340, Val Loss: 0.1696, Val Dice: 0.8504, Epoch Time: 6.09s\n",
      "Epoch [216/600], Train Loss: 0.2372, Val Loss: 0.1721, Val Dice: 0.8497, Epoch Time: 6.09s\n",
      "Epoch [217/600], Train Loss: 0.2428, Val Loss: 0.1656, Val Dice: 0.8550, Epoch Time: 6.12s\n",
      "Epoch [218/600], Train Loss: 0.2433, Val Loss: 0.1873, Val Dice: 0.8320, Epoch Time: 6.12s\n",
      "Epoch [219/600], Train Loss: 0.2473, Val Loss: 0.1656, Val Dice: 0.8526, Epoch Time: 6.06s\n",
      "Epoch [220/600], Train Loss: 0.2323, Val Loss: 0.1629, Val Dice: 0.8552, Epoch Time: 6.11s\n",
      "Epoch [221/600], Train Loss: 0.2272, Val Loss: 0.1604, Val Dice: 0.8576, Epoch Time: 6.08s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2272\n",
      "Epoch [222/600], Train Loss: 0.2249, Val Loss: 0.1578, Val Dice: 0.8612, Epoch Time: 6.05s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2249\n",
      "Epoch [223/600], Train Loss: 0.2330, Val Loss: 0.1730, Val Dice: 0.8467, Epoch Time: 6.00s\n",
      "Epoch [224/600], Train Loss: 0.2260, Val Loss: 0.1683, Val Dice: 0.8524, Epoch Time: 5.99s\n",
      "Epoch [225/600], Train Loss: 0.2427, Val Loss: 0.1668, Val Dice: 0.8528, Epoch Time: 5.72s\n",
      "Epoch [226/600], Train Loss: 0.2338, Val Loss: 0.1683, Val Dice: 0.8517, Epoch Time: 6.09s\n",
      "Epoch [227/600], Train Loss: 0.2376, Val Loss: 0.1637, Val Dice: 0.8555, Epoch Time: 6.12s\n",
      "Epoch [228/600], Train Loss: 0.2275, Val Loss: 0.1627, Val Dice: 0.8559, Epoch Time: 6.19s\n",
      "Epoch [229/600], Train Loss: 0.2298, Val Loss: 0.1606, Val Dice: 0.8580, Epoch Time: 6.02s\n",
      "Epoch [230/600], Train Loss: 0.2304, Val Loss: 0.1634, Val Dice: 0.8558, Epoch Time: 5.96s\n",
      "Epoch [231/600], Train Loss: 0.2244, Val Loss: 0.1547, Val Dice: 0.8627, Epoch Time: 6.02s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2244\n",
      "Epoch [232/600], Train Loss: 0.2248, Val Loss: 0.1661, Val Dice: 0.8525, Epoch Time: 6.16s\n",
      "Epoch [233/600], Train Loss: 0.2283, Val Loss: 0.1644, Val Dice: 0.8539, Epoch Time: 5.92s\n",
      "Epoch [234/600], Train Loss: 0.2295, Val Loss: 0.1615, Val Dice: 0.8586, Epoch Time: 5.97s\n",
      "Epoch [235/600], Train Loss: 0.2226, Val Loss: 0.1626, Val Dice: 0.8563, Epoch Time: 6.53s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2226\n",
      "Epoch [236/600], Train Loss: 0.2445, Val Loss: 0.1719, Val Dice: 0.8485, Epoch Time: 6.09s\n",
      "Epoch [237/600], Train Loss: 0.2345, Val Loss: 0.1678, Val Dice: 0.8544, Epoch Time: 5.94s\n",
      "Epoch [238/600], Train Loss: 0.2267, Val Loss: 0.1609, Val Dice: 0.8581, Epoch Time: 6.02s\n",
      "Epoch [239/600], Train Loss: 0.2217, Val Loss: 0.1598, Val Dice: 0.8593, Epoch Time: 6.07s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2217\n",
      "Epoch [240/600], Train Loss: 0.2253, Val Loss: 0.1613, Val Dice: 0.8562, Epoch Time: 6.01s\n",
      "Epoch [241/600], Train Loss: 0.2294, Val Loss: 0.1668, Val Dice: 0.8513, Epoch Time: 6.15s\n",
      "Epoch [242/600], Train Loss: 0.2406, Val Loss: 0.1774, Val Dice: 0.8456, Epoch Time: 6.06s\n",
      "Epoch [243/600], Train Loss: 0.2280, Val Loss: 0.1624, Val Dice: 0.8556, Epoch Time: 6.11s\n",
      "Epoch [244/600], Train Loss: 0.2261, Val Loss: 0.1629, Val Dice: 0.8553, Epoch Time: 5.79s\n",
      "Epoch [245/600], Train Loss: 0.2245, Val Loss: 0.1588, Val Dice: 0.8599, Epoch Time: 6.04s\n",
      "Epoch [246/600], Train Loss: 0.2217, Val Loss: 0.1625, Val Dice: 0.8581, Epoch Time: 6.07s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2217\n",
      "Epoch [247/600], Train Loss: 0.2225, Val Loss: 0.1639, Val Dice: 0.8556, Epoch Time: 6.07s\n",
      "Epoch [248/600], Train Loss: 0.2193, Val Loss: 0.1608, Val Dice: 0.8578, Epoch Time: 6.09s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2193\n",
      "Epoch [249/600], Train Loss: 0.2190, Val Loss: 0.1655, Val Dice: 0.8535, Epoch Time: 6.03s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2190\n",
      "Epoch [250/600], Train Loss: 0.2195, Val Loss: 0.1598, Val Dice: 0.8578, Epoch Time: 5.94s\n",
      "Epoch [251/600], Train Loss: 0.2223, Val Loss: 0.1524, Val Dice: 0.8652, Epoch Time: 6.15s\n",
      "Epoch [252/600], Train Loss: 0.2266, Val Loss: 0.1528, Val Dice: 0.8644, Epoch Time: 6.20s\n",
      "Epoch [253/600], Train Loss: 0.2215, Val Loss: 0.1611, Val Dice: 0.8561, Epoch Time: 5.80s\n",
      "Epoch [254/600], Train Loss: 0.2186, Val Loss: 0.1627, Val Dice: 0.8568, Epoch Time: 6.01s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2186\n",
      "Epoch [255/600], Train Loss: 0.2252, Val Loss: 0.1729, Val Dice: 0.8486, Epoch Time: 6.18s\n",
      "Epoch [256/600], Train Loss: 0.2236, Val Loss: 0.1558, Val Dice: 0.8623, Epoch Time: 6.02s\n",
      "Epoch [257/600], Train Loss: 0.2306, Val Loss: 0.1606, Val Dice: 0.8573, Epoch Time: 6.18s\n",
      "Epoch [258/600], Train Loss: 0.2195, Val Loss: 0.1619, Val Dice: 0.8568, Epoch Time: 6.01s\n",
      "Epoch [259/600], Train Loss: 0.2196, Val Loss: 0.1669, Val Dice: 0.8506, Epoch Time: 6.30s\n",
      "Epoch [260/600], Train Loss: 0.2169, Val Loss: 0.1602, Val Dice: 0.8582, Epoch Time: 6.13s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2169\n",
      "Epoch [261/600], Train Loss: 0.2152, Val Loss: 0.1582, Val Dice: 0.8613, Epoch Time: 6.14s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2152\n",
      "Epoch [262/600], Train Loss: 0.2125, Val Loss: 0.1590, Val Dice: 0.8585, Epoch Time: 6.21s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2125\n",
      "Epoch [263/600], Train Loss: 0.2095, Val Loss: 0.1568, Val Dice: 0.8608, Epoch Time: 5.89s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2095\n",
      "Epoch [264/600], Train Loss: 0.2140, Val Loss: 0.1594, Val Dice: 0.8590, Epoch Time: 6.00s\n",
      "Epoch [265/600], Train Loss: 0.2092, Val Loss: 0.1601, Val Dice: 0.8576, Epoch Time: 5.98s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2092\n",
      "Epoch [266/600], Train Loss: 0.2087, Val Loss: 0.1602, Val Dice: 0.8565, Epoch Time: 6.00s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2087\n",
      "Epoch [267/600], Train Loss: 0.2109, Val Loss: 0.1577, Val Dice: 0.8590, Epoch Time: 6.03s\n",
      "Epoch [268/600], Train Loss: 0.2102, Val Loss: 0.1563, Val Dice: 0.8614, Epoch Time: 5.88s\n",
      "Epoch [269/600], Train Loss: 0.2110, Val Loss: 0.1622, Val Dice: 0.8555, Epoch Time: 6.12s\n",
      "Epoch [270/600], Train Loss: 0.2114, Val Loss: 0.1541, Val Dice: 0.8636, Epoch Time: 5.98s\n",
      "Epoch [271/600], Train Loss: 0.2093, Val Loss: 0.1571, Val Dice: 0.8607, Epoch Time: 5.99s\n",
      "Epoch [272/600], Train Loss: 0.2076, Val Loss: 0.1610, Val Dice: 0.8574, Epoch Time: 6.21s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2076\n",
      "Epoch [273/600], Train Loss: 0.2119, Val Loss: 0.1506, Val Dice: 0.8686, Epoch Time: 5.99s\n",
      "Epoch [274/600], Train Loss: 0.2091, Val Loss: 0.1586, Val Dice: 0.8610, Epoch Time: 5.90s\n",
      "Epoch [275/600], Train Loss: 0.2082, Val Loss: 0.1543, Val Dice: 0.8626, Epoch Time: 6.07s\n",
      "Epoch [276/600], Train Loss: 0.2132, Val Loss: 0.1555, Val Dice: 0.8640, Epoch Time: 5.96s\n",
      "Epoch [277/600], Train Loss: 0.2026, Val Loss: 0.1663, Val Dice: 0.8496, Epoch Time: 5.73s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2026\n",
      "Epoch [278/600], Train Loss: 0.2099, Val Loss: 0.1572, Val Dice: 0.8605, Epoch Time: 5.85s\n",
      "Epoch [279/600], Train Loss: 0.2072, Val Loss: 0.1547, Val Dice: 0.8635, Epoch Time: 6.18s\n",
      "Epoch [280/600], Train Loss: 0.2264, Val Loss: 0.1625, Val Dice: 0.8576, Epoch Time: 6.20s\n",
      "Epoch [281/600], Train Loss: 0.2104, Val Loss: 0.1573, Val Dice: 0.8603, Epoch Time: 6.06s\n",
      "Epoch [282/600], Train Loss: 0.2133, Val Loss: 0.1558, Val Dice: 0.8619, Epoch Time: 6.05s\n",
      "Epoch [283/600], Train Loss: 0.2138, Val Loss: 0.1556, Val Dice: 0.8630, Epoch Time: 6.03s\n",
      "Epoch [284/600], Train Loss: 0.2115, Val Loss: 0.1681, Val Dice: 0.8508, Epoch Time: 5.98s\n",
      "Epoch [285/600], Train Loss: 0.2029, Val Loss: 0.1591, Val Dice: 0.8606, Epoch Time: 6.14s\n",
      "Epoch [286/600], Train Loss: 0.2086, Val Loss: 0.1732, Val Dice: 0.8483, Epoch Time: 5.89s\n",
      "Epoch [287/600], Train Loss: 0.2126, Val Loss: 0.1552, Val Dice: 0.8634, Epoch Time: 6.15s\n",
      "Epoch [288/600], Train Loss: 0.2118, Val Loss: 0.1590, Val Dice: 0.8587, Epoch Time: 6.03s\n",
      "Epoch [289/600], Train Loss: 0.2057, Val Loss: 0.1519, Val Dice: 0.8660, Epoch Time: 6.03s\n",
      "Epoch [290/600], Train Loss: 0.2004, Val Loss: 0.1544, Val Dice: 0.8631, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2004\n",
      "Epoch [291/600], Train Loss: 0.2061, Val Loss: 0.1523, Val Dice: 0.8658, Epoch Time: 5.92s\n",
      "Epoch [292/600], Train Loss: 0.2067, Val Loss: 0.1549, Val Dice: 0.8625, Epoch Time: 5.94s\n",
      "Epoch [293/600], Train Loss: 0.2000, Val Loss: 0.1523, Val Dice: 0.8646, Epoch Time: 6.10s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.2000\n",
      "Epoch [294/600], Train Loss: 0.1983, Val Loss: 0.1540, Val Dice: 0.8643, Epoch Time: 5.91s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1983\n",
      "Epoch [295/600], Train Loss: 0.2049, Val Loss: 0.1561, Val Dice: 0.8632, Epoch Time: 5.68s\n",
      "Epoch [296/600], Train Loss: 0.2047, Val Loss: 0.1535, Val Dice: 0.8634, Epoch Time: 5.95s\n",
      "Epoch [297/600], Train Loss: 0.2041, Val Loss: 0.1524, Val Dice: 0.8656, Epoch Time: 5.95s\n",
      "Epoch [298/600], Train Loss: 0.2006, Val Loss: 0.1536, Val Dice: 0.8637, Epoch Time: 5.89s\n",
      "Epoch [299/600], Train Loss: 0.2022, Val Loss: 0.1605, Val Dice: 0.8590, Epoch Time: 5.99s\n",
      "Epoch [300/600], Train Loss: 0.2080, Val Loss: 0.1558, Val Dice: 0.8621, Epoch Time: 6.05s\n",
      "Epoch [301/600], Train Loss: 0.1991, Val Loss: 0.1549, Val Dice: 0.8636, Epoch Time: 6.41s\n",
      "Epoch [302/600], Train Loss: 0.2127, Val Loss: 0.1540, Val Dice: 0.8647, Epoch Time: 6.04s\n",
      "Epoch [303/600], Train Loss: 0.1985, Val Loss: 0.1596, Val Dice: 0.8599, Epoch Time: 6.15s\n",
      "Epoch [304/600], Train Loss: 0.1998, Val Loss: 0.1562, Val Dice: 0.8635, Epoch Time: 6.09s\n",
      "Epoch [305/600], Train Loss: 0.1965, Val Loss: 0.1500, Val Dice: 0.8677, Epoch Time: 6.00s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1965\n",
      "Epoch [306/600], Train Loss: 0.1936, Val Loss: 0.1528, Val Dice: 0.8645, Epoch Time: 6.37s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1936\n",
      "Epoch [307/600], Train Loss: 0.1944, Val Loss: 0.1522, Val Dice: 0.8653, Epoch Time: 6.00s\n",
      "Epoch [308/600], Train Loss: 0.1951, Val Loss: 0.1488, Val Dice: 0.8686, Epoch Time: 5.82s\n",
      "Epoch [309/600], Train Loss: 0.1899, Val Loss: 0.1507, Val Dice: 0.8671, Epoch Time: 5.88s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1899\n",
      "Epoch [310/600], Train Loss: 0.1936, Val Loss: 0.1548, Val Dice: 0.8631, Epoch Time: 6.07s\n",
      "Epoch [311/600], Train Loss: 0.1914, Val Loss: 0.1517, Val Dice: 0.8665, Epoch Time: 6.22s\n",
      "Epoch [312/600], Train Loss: 0.1933, Val Loss: 0.1547, Val Dice: 0.8630, Epoch Time: 5.97s\n",
      "Epoch [313/600], Train Loss: 0.1924, Val Loss: 0.1581, Val Dice: 0.8588, Epoch Time: 5.95s\n",
      "Epoch [314/600], Train Loss: 0.1912, Val Loss: 0.1540, Val Dice: 0.8642, Epoch Time: 6.10s\n",
      "Epoch [315/600], Train Loss: 0.1933, Val Loss: 0.1512, Val Dice: 0.8666, Epoch Time: 5.82s\n",
      "Epoch [316/600], Train Loss: 0.1921, Val Loss: 0.1525, Val Dice: 0.8654, Epoch Time: 6.08s\n",
      "Epoch [317/600], Train Loss: 0.1978, Val Loss: 0.1552, Val Dice: 0.8620, Epoch Time: 6.16s\n",
      "Epoch [318/600], Train Loss: 0.1966, Val Loss: 0.1517, Val Dice: 0.8664, Epoch Time: 6.45s\n",
      "Epoch [319/600], Train Loss: 0.1916, Val Loss: 0.1477, Val Dice: 0.8703, Epoch Time: 6.03s\n",
      "Epoch [320/600], Train Loss: 0.1979, Val Loss: 0.1490, Val Dice: 0.8689, Epoch Time: 5.70s\n",
      "Epoch [321/600], Train Loss: 0.1902, Val Loss: 0.1499, Val Dice: 0.8678, Epoch Time: 5.95s\n",
      "Epoch [322/600], Train Loss: 0.1938, Val Loss: 0.1534, Val Dice: 0.8633, Epoch Time: 6.06s\n",
      "Epoch [323/600], Train Loss: 0.1873, Val Loss: 0.1546, Val Dice: 0.8623, Epoch Time: 5.96s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1873\n",
      "Epoch [324/600], Train Loss: 0.2101, Val Loss: 0.1879, Val Dice: 0.8328, Epoch Time: 6.01s\n",
      "Epoch [325/600], Train Loss: 0.2001, Val Loss: 0.1539, Val Dice: 0.8648, Epoch Time: 6.04s\n",
      "Epoch [326/600], Train Loss: 0.1942, Val Loss: 0.1535, Val Dice: 0.8643, Epoch Time: 6.09s\n",
      "Epoch [327/600], Train Loss: 0.2058, Val Loss: 0.1630, Val Dice: 0.8566, Epoch Time: 6.15s\n",
      "Epoch [328/600], Train Loss: 0.1995, Val Loss: 0.1557, Val Dice: 0.8625, Epoch Time: 5.96s\n",
      "Epoch [329/600], Train Loss: 0.1943, Val Loss: 0.1554, Val Dice: 0.8646, Epoch Time: 6.22s\n",
      "Epoch [330/600], Train Loss: 0.1935, Val Loss: 0.1537, Val Dice: 0.8651, Epoch Time: 6.16s\n",
      "Epoch [331/600], Train Loss: 0.1903, Val Loss: 0.1489, Val Dice: 0.8697, Epoch Time: 6.17s\n",
      "Epoch [332/600], Train Loss: 0.1888, Val Loss: 0.1507, Val Dice: 0.8674, Epoch Time: 5.89s\n",
      "Epoch [333/600], Train Loss: 0.1897, Val Loss: 0.1510, Val Dice: 0.8670, Epoch Time: 6.05s\n",
      "Epoch [334/600], Train Loss: 0.1949, Val Loss: 0.1521, Val Dice: 0.8641, Epoch Time: 6.22s\n",
      "Epoch [335/600], Train Loss: 0.1859, Val Loss: 0.1527, Val Dice: 0.8644, Epoch Time: 6.00s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1859\n",
      "Epoch [336/600], Train Loss: 0.1952, Val Loss: 0.1478, Val Dice: 0.8693, Epoch Time: 6.07s\n",
      "Epoch [337/600], Train Loss: 0.1885, Val Loss: 0.1431, Val Dice: 0.8737, Epoch Time: 6.03s\n",
      "Epoch [338/600], Train Loss: 0.1878, Val Loss: 0.1453, Val Dice: 0.8717, Epoch Time: 6.02s\n",
      "Epoch [339/600], Train Loss: 0.1954, Val Loss: 0.1553, Val Dice: 0.8632, Epoch Time: 6.06s\n",
      "Epoch [340/600], Train Loss: 0.1897, Val Loss: 0.1484, Val Dice: 0.8700, Epoch Time: 5.99s\n",
      "Epoch [341/600], Train Loss: 0.1907, Val Loss: 0.1577, Val Dice: 0.8626, Epoch Time: 6.00s\n",
      "Epoch [342/600], Train Loss: 0.1899, Val Loss: 0.1559, Val Dice: 0.8630, Epoch Time: 5.98s\n",
      "Epoch [343/600], Train Loss: 0.1853, Val Loss: 0.1541, Val Dice: 0.8644, Epoch Time: 5.92s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1853\n",
      "Epoch [344/600], Train Loss: 0.1861, Val Loss: 0.1536, Val Dice: 0.8646, Epoch Time: 5.85s\n",
      "Epoch [345/600], Train Loss: 0.1915, Val Loss: 0.1497, Val Dice: 0.8679, Epoch Time: 6.09s\n",
      "Epoch [346/600], Train Loss: 0.1883, Val Loss: 0.1518, Val Dice: 0.8663, Epoch Time: 5.94s\n",
      "Epoch [347/600], Train Loss: 0.1856, Val Loss: 0.1524, Val Dice: 0.8671, Epoch Time: 6.06s\n",
      "Epoch [348/600], Train Loss: 0.1840, Val Loss: 0.1505, Val Dice: 0.8670, Epoch Time: 6.24s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1840\n",
      "Epoch [349/600], Train Loss: 0.1842, Val Loss: 0.1481, Val Dice: 0.8693, Epoch Time: 6.12s\n",
      "Epoch [350/600], Train Loss: 0.1856, Val Loss: 0.1511, Val Dice: 0.8675, Epoch Time: 5.89s\n",
      "Epoch [351/600], Train Loss: 0.1838, Val Loss: 0.1489, Val Dice: 0.8690, Epoch Time: 5.98s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1838\n",
      "Epoch [352/600], Train Loss: 0.1849, Val Loss: 0.1505, Val Dice: 0.8676, Epoch Time: 6.11s\n",
      "Epoch [353/600], Train Loss: 0.1885, Val Loss: 0.1485, Val Dice: 0.8676, Epoch Time: 5.95s\n",
      "Epoch [354/600], Train Loss: 0.1839, Val Loss: 0.1486, Val Dice: 0.8678, Epoch Time: 5.92s\n",
      "Epoch [355/600], Train Loss: 0.1810, Val Loss: 0.1518, Val Dice: 0.8650, Epoch Time: 6.09s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1810\n",
      "Epoch [356/600], Train Loss: 0.1811, Val Loss: 0.1480, Val Dice: 0.8688, Epoch Time: 6.06s\n",
      "Epoch [357/600], Train Loss: 0.1829, Val Loss: 0.1463, Val Dice: 0.8727, Epoch Time: 5.96s\n",
      "Epoch [358/600], Train Loss: 0.1798, Val Loss: 0.1528, Val Dice: 0.8670, Epoch Time: 5.97s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1798\n",
      "Epoch [359/600], Train Loss: 0.1813, Val Loss: 0.1487, Val Dice: 0.8683, Epoch Time: 6.06s\n",
      "Epoch [360/600], Train Loss: 0.1831, Val Loss: 0.1504, Val Dice: 0.8673, Epoch Time: 5.91s\n",
      "Epoch [361/600], Train Loss: 0.1797, Val Loss: 0.1503, Val Dice: 0.8677, Epoch Time: 5.91s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1797\n",
      "Epoch [362/600], Train Loss: 0.1814, Val Loss: 0.1430, Val Dice: 0.8751, Epoch Time: 6.26s\n",
      "Epoch [363/600], Train Loss: 0.1787, Val Loss: 0.1446, Val Dice: 0.8724, Epoch Time: 6.09s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1787\n",
      "Epoch [364/600], Train Loss: 0.1804, Val Loss: 0.1493, Val Dice: 0.8699, Epoch Time: 6.17s\n",
      "Epoch [365/600], Train Loss: 0.1834, Val Loss: 0.1507, Val Dice: 0.8685, Epoch Time: 6.21s\n",
      "Epoch [366/600], Train Loss: 0.1823, Val Loss: 0.1506, Val Dice: 0.8676, Epoch Time: 5.86s\n",
      "Epoch [367/600], Train Loss: 0.1823, Val Loss: 0.1510, Val Dice: 0.8677, Epoch Time: 6.06s\n",
      "Epoch [368/600], Train Loss: 0.1797, Val Loss: 0.1486, Val Dice: 0.8689, Epoch Time: 5.90s\n",
      "Epoch [369/600], Train Loss: 0.1800, Val Loss: 0.1458, Val Dice: 0.8717, Epoch Time: 6.19s\n",
      "Epoch [370/600], Train Loss: 0.1773, Val Loss: 0.1460, Val Dice: 0.8713, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1773\n",
      "Epoch [371/600], Train Loss: 0.1781, Val Loss: 0.1473, Val Dice: 0.8692, Epoch Time: 6.05s\n",
      "Epoch [372/600], Train Loss: 0.1781, Val Loss: 0.1462, Val Dice: 0.8721, Epoch Time: 6.24s\n",
      "Epoch [373/600], Train Loss: 0.1753, Val Loss: 0.1451, Val Dice: 0.8739, Epoch Time: 6.07s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1753\n",
      "Epoch [374/600], Train Loss: 0.1761, Val Loss: 0.1470, Val Dice: 0.8708, Epoch Time: 6.07s\n",
      "Epoch [375/600], Train Loss: 0.1751, Val Loss: 0.1462, Val Dice: 0.8710, Epoch Time: 5.98s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1751\n",
      "Epoch [376/600], Train Loss: 0.1804, Val Loss: 0.1462, Val Dice: 0.8718, Epoch Time: 6.03s\n",
      "Epoch [377/600], Train Loss: 0.1773, Val Loss: 0.1483, Val Dice: 0.8694, Epoch Time: 6.14s\n",
      "Epoch [378/600], Train Loss: 0.1781, Val Loss: 0.1487, Val Dice: 0.8705, Epoch Time: 5.95s\n",
      "Epoch [379/600], Train Loss: 0.1785, Val Loss: 0.1497, Val Dice: 0.8683, Epoch Time: 5.85s\n",
      "Epoch [380/600], Train Loss: 0.1783, Val Loss: 0.1434, Val Dice: 0.8737, Epoch Time: 5.82s\n",
      "Epoch [381/600], Train Loss: 0.1769, Val Loss: 0.1470, Val Dice: 0.8701, Epoch Time: 5.81s\n",
      "Epoch [382/600], Train Loss: 0.1768, Val Loss: 0.1434, Val Dice: 0.8740, Epoch Time: 6.00s\n",
      "Epoch [383/600], Train Loss: 0.1733, Val Loss: 0.1453, Val Dice: 0.8732, Epoch Time: 5.95s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1733\n",
      "Epoch [384/600], Train Loss: 0.1736, Val Loss: 0.1450, Val Dice: 0.8733, Epoch Time: 6.10s\n",
      "Epoch [385/600], Train Loss: 0.1756, Val Loss: 0.1450, Val Dice: 0.8725, Epoch Time: 6.01s\n",
      "Epoch [386/600], Train Loss: 0.1732, Val Loss: 0.1467, Val Dice: 0.8709, Epoch Time: 6.08s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1732\n",
      "Epoch [387/600], Train Loss: 0.1723, Val Loss: 0.1423, Val Dice: 0.8749, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1723\n",
      "Epoch [388/600], Train Loss: 0.1731, Val Loss: 0.1503, Val Dice: 0.8662, Epoch Time: 5.98s\n",
      "Epoch [389/600], Train Loss: 0.1804, Val Loss: 0.1637, Val Dice: 0.8562, Epoch Time: 5.83s\n",
      "Epoch [390/600], Train Loss: 0.1779, Val Loss: 0.1500, Val Dice: 0.8682, Epoch Time: 5.99s\n",
      "Epoch [391/600], Train Loss: 0.1736, Val Loss: 0.1478, Val Dice: 0.8698, Epoch Time: 6.01s\n",
      "Epoch [392/600], Train Loss: 0.1738, Val Loss: 0.1527, Val Dice: 0.8673, Epoch Time: 6.06s\n",
      "Epoch [393/600], Train Loss: 0.1743, Val Loss: 0.1478, Val Dice: 0.8692, Epoch Time: 5.82s\n",
      "Epoch [394/600], Train Loss: 0.1721, Val Loss: 0.1447, Val Dice: 0.8725, Epoch Time: 6.14s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1721\n",
      "Epoch [395/600], Train Loss: 0.1721, Val Loss: 0.1445, Val Dice: 0.8737, Epoch Time: 6.03s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1721\n",
      "Epoch [396/600], Train Loss: 0.1719, Val Loss: 0.1433, Val Dice: 0.8738, Epoch Time: 6.29s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1719\n",
      "Epoch [397/600], Train Loss: 0.1714, Val Loss: 0.1449, Val Dice: 0.8730, Epoch Time: 6.36s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1714\n",
      "Epoch [398/600], Train Loss: 0.1694, Val Loss: 0.1452, Val Dice: 0.8728, Epoch Time: 6.20s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1694\n",
      "Epoch [399/600], Train Loss: 0.1754, Val Loss: 0.1411, Val Dice: 0.8765, Epoch Time: 6.21s\n",
      "Epoch [400/600], Train Loss: 0.1687, Val Loss: 0.1476, Val Dice: 0.8701, Epoch Time: 6.14s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1687\n",
      "Epoch [401/600], Train Loss: 0.1695, Val Loss: 0.1414, Val Dice: 0.8760, Epoch Time: 5.95s\n",
      "Epoch [402/600], Train Loss: 0.1708, Val Loss: 0.1445, Val Dice: 0.8733, Epoch Time: 6.07s\n",
      "Epoch [403/600], Train Loss: 0.1694, Val Loss: 0.1468, Val Dice: 0.8703, Epoch Time: 5.86s\n",
      "Epoch [404/600], Train Loss: 0.1764, Val Loss: 0.1454, Val Dice: 0.8716, Epoch Time: 6.18s\n",
      "Epoch [405/600], Train Loss: 0.1700, Val Loss: 0.1466, Val Dice: 0.8714, Epoch Time: 6.09s\n",
      "Epoch [406/600], Train Loss: 0.1736, Val Loss: 0.1461, Val Dice: 0.8721, Epoch Time: 6.13s\n",
      "Epoch [407/600], Train Loss: 0.1701, Val Loss: 0.1460, Val Dice: 0.8731, Epoch Time: 6.17s\n",
      "Epoch [408/600], Train Loss: 0.1696, Val Loss: 0.1467, Val Dice: 0.8715, Epoch Time: 6.08s\n",
      "Epoch [409/600], Train Loss: 0.1681, Val Loss: 0.1441, Val Dice: 0.8753, Epoch Time: 5.78s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1681\n",
      "Epoch [410/600], Train Loss: 0.1694, Val Loss: 0.1452, Val Dice: 0.8731, Epoch Time: 6.01s\n",
      "Epoch [411/600], Train Loss: 0.1670, Val Loss: 0.1447, Val Dice: 0.8733, Epoch Time: 6.02s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1670\n",
      "Epoch [412/600], Train Loss: 0.1672, Val Loss: 0.1453, Val Dice: 0.8726, Epoch Time: 5.77s\n",
      "Epoch [413/600], Train Loss: 0.1690, Val Loss: 0.1427, Val Dice: 0.8761, Epoch Time: 5.82s\n",
      "Epoch [414/600], Train Loss: 0.1653, Val Loss: 0.1414, Val Dice: 0.8768, Epoch Time: 6.13s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1653\n",
      "Epoch [415/600], Train Loss: 0.1663, Val Loss: 0.1459, Val Dice: 0.8733, Epoch Time: 6.05s\n",
      "Epoch [416/600], Train Loss: 0.1676, Val Loss: 0.1462, Val Dice: 0.8724, Epoch Time: 6.04s\n",
      "Epoch [417/600], Train Loss: 0.1686, Val Loss: 0.1442, Val Dice: 0.8743, Epoch Time: 6.14s\n",
      "Epoch [418/600], Train Loss: 0.1661, Val Loss: 0.1461, Val Dice: 0.8727, Epoch Time: 6.15s\n",
      "Epoch [419/600], Train Loss: 0.1649, Val Loss: 0.1435, Val Dice: 0.8752, Epoch Time: 6.21s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1649\n",
      "Epoch [420/600], Train Loss: 0.1678, Val Loss: 0.1444, Val Dice: 0.8759, Epoch Time: 6.11s\n",
      "Epoch [421/600], Train Loss: 0.1654, Val Loss: 0.1431, Val Dice: 0.8750, Epoch Time: 6.18s\n",
      "Epoch [422/600], Train Loss: 0.1654, Val Loss: 0.1437, Val Dice: 0.8754, Epoch Time: 5.94s\n",
      "Epoch [423/600], Train Loss: 0.1636, Val Loss: 0.1435, Val Dice: 0.8752, Epoch Time: 6.01s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1636\n",
      "Epoch [424/600], Train Loss: 0.1664, Val Loss: 0.1421, Val Dice: 0.8768, Epoch Time: 6.03s\n",
      "Epoch [425/600], Train Loss: 0.1698, Val Loss: 0.1476, Val Dice: 0.8717, Epoch Time: 6.34s\n",
      "Epoch [426/600], Train Loss: 0.1654, Val Loss: 0.1452, Val Dice: 0.8733, Epoch Time: 6.02s\n",
      "Epoch [427/600], Train Loss: 0.1631, Val Loss: 0.1450, Val Dice: 0.8735, Epoch Time: 5.87s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1631\n",
      "Epoch [428/600], Train Loss: 0.1649, Val Loss: 0.1443, Val Dice: 0.8752, Epoch Time: 5.93s\n",
      "Epoch [429/600], Train Loss: 0.1664, Val Loss: 0.1460, Val Dice: 0.8728, Epoch Time: 6.06s\n",
      "Epoch [430/600], Train Loss: 0.1664, Val Loss: 0.1427, Val Dice: 0.8761, Epoch Time: 5.92s\n",
      "Epoch [431/600], Train Loss: 0.1698, Val Loss: 0.1433, Val Dice: 0.8750, Epoch Time: 6.06s\n",
      "Epoch [432/600], Train Loss: 0.1633, Val Loss: 0.1473, Val Dice: 0.8720, Epoch Time: 5.82s\n",
      "Epoch [433/600], Train Loss: 0.1673, Val Loss: 0.1473, Val Dice: 0.8715, Epoch Time: 6.08s\n",
      "Epoch [434/600], Train Loss: 0.1641, Val Loss: 0.1472, Val Dice: 0.8720, Epoch Time: 6.25s\n",
      "Epoch [435/600], Train Loss: 0.1637, Val Loss: 0.1435, Val Dice: 0.8743, Epoch Time: 6.02s\n",
      "Epoch [436/600], Train Loss: 0.1609, Val Loss: 0.1438, Val Dice: 0.8755, Epoch Time: 5.92s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1609\n",
      "Epoch [437/600], Train Loss: 0.1639, Val Loss: 0.1414, Val Dice: 0.8768, Epoch Time: 6.07s\n",
      "Epoch [438/600], Train Loss: 0.1687, Val Loss: 0.1460, Val Dice: 0.8727, Epoch Time: 6.03s\n",
      "Epoch [439/600], Train Loss: 0.1654, Val Loss: 0.1450, Val Dice: 0.8738, Epoch Time: 6.19s\n",
      "Epoch [440/600], Train Loss: 0.1628, Val Loss: 0.1445, Val Dice: 0.8745, Epoch Time: 5.75s\n",
      "Epoch [441/600], Train Loss: 0.1643, Val Loss: 0.1446, Val Dice: 0.8753, Epoch Time: 6.14s\n",
      "Epoch [442/600], Train Loss: 0.1635, Val Loss: 0.1441, Val Dice: 0.8755, Epoch Time: 6.12s\n",
      "Epoch [443/600], Train Loss: 0.1627, Val Loss: 0.1437, Val Dice: 0.8748, Epoch Time: 6.13s\n",
      "Epoch [444/600], Train Loss: 0.1596, Val Loss: 0.1417, Val Dice: 0.8767, Epoch Time: 6.08s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1596\n",
      "Epoch [445/600], Train Loss: 0.1614, Val Loss: 0.1433, Val Dice: 0.8763, Epoch Time: 6.10s\n",
      "Epoch [446/600], Train Loss: 0.1614, Val Loss: 0.1436, Val Dice: 0.8758, Epoch Time: 6.06s\n",
      "Epoch [447/600], Train Loss: 0.1666, Val Loss: 0.1431, Val Dice: 0.8748, Epoch Time: 6.06s\n",
      "Epoch [448/600], Train Loss: 0.1623, Val Loss: 0.1458, Val Dice: 0.8736, Epoch Time: 6.21s\n",
      "Epoch [449/600], Train Loss: 0.1614, Val Loss: 0.1421, Val Dice: 0.8761, Epoch Time: 6.26s\n",
      "Epoch [450/600], Train Loss: 0.1635, Val Loss: 0.1433, Val Dice: 0.8756, Epoch Time: 6.31s\n",
      "Epoch [451/600], Train Loss: 0.1631, Val Loss: 0.1472, Val Dice: 0.8715, Epoch Time: 6.05s\n",
      "Epoch [452/600], Train Loss: 0.1641, Val Loss: 0.1440, Val Dice: 0.8753, Epoch Time: 6.05s\n",
      "Epoch [453/600], Train Loss: 0.1614, Val Loss: 0.1426, Val Dice: 0.8765, Epoch Time: 5.77s\n",
      "Epoch [454/600], Train Loss: 0.1673, Val Loss: 0.1444, Val Dice: 0.8737, Epoch Time: 5.86s\n",
      "Epoch [455/600], Train Loss: 0.1607, Val Loss: 0.1438, Val Dice: 0.8749, Epoch Time: 6.08s\n",
      "Epoch [456/600], Train Loss: 0.1589, Val Loss: 0.1443, Val Dice: 0.8739, Epoch Time: 6.15s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1589\n",
      "Epoch [457/600], Train Loss: 0.1631, Val Loss: 0.1431, Val Dice: 0.8762, Epoch Time: 5.85s\n",
      "Epoch [458/600], Train Loss: 0.1612, Val Loss: 0.1426, Val Dice: 0.8763, Epoch Time: 6.06s\n",
      "Epoch [459/600], Train Loss: 0.1614, Val Loss: 0.1439, Val Dice: 0.8753, Epoch Time: 6.07s\n",
      "Epoch [460/600], Train Loss: 0.1662, Val Loss: 0.1431, Val Dice: 0.8766, Epoch Time: 6.06s\n",
      "Epoch [461/600], Train Loss: 0.1631, Val Loss: 0.1422, Val Dice: 0.8762, Epoch Time: 6.03s\n",
      "Epoch [462/600], Train Loss: 0.1627, Val Loss: 0.1456, Val Dice: 0.8738, Epoch Time: 5.94s\n",
      "Epoch [463/600], Train Loss: 0.1617, Val Loss: 0.1423, Val Dice: 0.8767, Epoch Time: 6.01s\n",
      "Epoch [464/600], Train Loss: 0.1596, Val Loss: 0.1419, Val Dice: 0.8774, Epoch Time: 6.05s\n",
      "Epoch [465/600], Train Loss: 0.1600, Val Loss: 0.1427, Val Dice: 0.8765, Epoch Time: 6.03s\n",
      "Epoch [466/600], Train Loss: 0.1601, Val Loss: 0.1432, Val Dice: 0.8748, Epoch Time: 5.97s\n",
      "Epoch [467/600], Train Loss: 0.1601, Val Loss: 0.1438, Val Dice: 0.8749, Epoch Time: 5.92s\n",
      "Epoch [468/600], Train Loss: 0.1597, Val Loss: 0.1428, Val Dice: 0.8765, Epoch Time: 5.92s\n",
      "Epoch [469/600], Train Loss: 0.1592, Val Loss: 0.1427, Val Dice: 0.8769, Epoch Time: 5.98s\n",
      "Epoch [470/600], Train Loss: 0.1618, Val Loss: 0.1420, Val Dice: 0.8778, Epoch Time: 6.26s\n",
      "Epoch [471/600], Train Loss: 0.1617, Val Loss: 0.1441, Val Dice: 0.8760, Epoch Time: 6.05s\n",
      "Epoch [472/600], Train Loss: 0.1606, Val Loss: 0.1451, Val Dice: 0.8738, Epoch Time: 6.19s\n",
      "Epoch [473/600], Train Loss: 0.1585, Val Loss: 0.1415, Val Dice: 0.8769, Epoch Time: 6.29s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1585\n",
      "Epoch [474/600], Train Loss: 0.1606, Val Loss: 0.1447, Val Dice: 0.8737, Epoch Time: 5.89s\n",
      "Epoch [475/600], Train Loss: 0.1610, Val Loss: 0.1414, Val Dice: 0.8780, Epoch Time: 6.09s\n",
      "Epoch [476/600], Train Loss: 0.1650, Val Loss: 0.1434, Val Dice: 0.8755, Epoch Time: 5.82s\n",
      "Epoch [477/600], Train Loss: 0.1589, Val Loss: 0.1439, Val Dice: 0.8761, Epoch Time: 6.02s\n",
      "Epoch [478/600], Train Loss: 0.1614, Val Loss: 0.1448, Val Dice: 0.8753, Epoch Time: 6.08s\n",
      "Epoch [479/600], Train Loss: 0.1596, Val Loss: 0.1417, Val Dice: 0.8769, Epoch Time: 6.02s\n",
      "Epoch [480/600], Train Loss: 0.1610, Val Loss: 0.1439, Val Dice: 0.8759, Epoch Time: 5.77s\n",
      "Epoch [481/600], Train Loss: 0.1603, Val Loss: 0.1464, Val Dice: 0.8737, Epoch Time: 5.98s\n",
      "Epoch [482/600], Train Loss: 0.1611, Val Loss: 0.1435, Val Dice: 0.8757, Epoch Time: 6.09s\n",
      "Epoch [483/600], Train Loss: 0.1601, Val Loss: 0.1432, Val Dice: 0.8754, Epoch Time: 6.22s\n",
      "Epoch [484/600], Train Loss: 0.1602, Val Loss: 0.1424, Val Dice: 0.8763, Epoch Time: 5.95s\n",
      "Epoch [485/600], Train Loss: 0.1637, Val Loss: 0.1455, Val Dice: 0.8735, Epoch Time: 5.96s\n",
      "Epoch [486/600], Train Loss: 0.1646, Val Loss: 0.1441, Val Dice: 0.8762, Epoch Time: 6.10s\n",
      "Epoch [487/600], Train Loss: 0.1661, Val Loss: 0.1402, Val Dice: 0.8790, Epoch Time: 5.97s\n",
      "Epoch [488/600], Train Loss: 0.1604, Val Loss: 0.1423, Val Dice: 0.8769, Epoch Time: 5.77s\n",
      "Epoch [489/600], Train Loss: 0.1587, Val Loss: 0.1456, Val Dice: 0.8752, Epoch Time: 6.00s\n",
      "Epoch [490/600], Train Loss: 0.1591, Val Loss: 0.1434, Val Dice: 0.8758, Epoch Time: 5.94s\n",
      "Epoch [491/600], Train Loss: 0.1601, Val Loss: 0.1426, Val Dice: 0.8757, Epoch Time: 6.21s\n",
      "Epoch [492/600], Train Loss: 0.1596, Val Loss: 0.1443, Val Dice: 0.8761, Epoch Time: 6.11s\n",
      "Epoch [493/600], Train Loss: 0.1619, Val Loss: 0.1431, Val Dice: 0.8762, Epoch Time: 6.22s\n",
      "Epoch [494/600], Train Loss: 0.1588, Val Loss: 0.1434, Val Dice: 0.8758, Epoch Time: 6.15s\n",
      "Epoch [495/600], Train Loss: 0.1600, Val Loss: 0.1459, Val Dice: 0.8742, Epoch Time: 6.11s\n",
      "Epoch [496/600], Train Loss: 0.1588, Val Loss: 0.1456, Val Dice: 0.8745, Epoch Time: 6.19s\n",
      "Epoch [497/600], Train Loss: 0.1660, Val Loss: 0.1430, Val Dice: 0.8776, Epoch Time: 5.98s\n",
      "Epoch [498/600], Train Loss: 0.1576, Val Loss: 0.1443, Val Dice: 0.8752, Epoch Time: 6.12s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1576\n",
      "Epoch [499/600], Train Loss: 0.1580, Val Loss: 0.1434, Val Dice: 0.8763, Epoch Time: 5.83s\n",
      "Epoch [500/600], Train Loss: 0.1584, Val Loss: 0.1399, Val Dice: 0.8800, Epoch Time: 6.17s\n",
      "Epoch [501/600], Train Loss: 0.1635, Val Loss: 0.1426, Val Dice: 0.8767, Epoch Time: 6.17s\n",
      "Epoch [502/600], Train Loss: 0.1570, Val Loss: 0.1451, Val Dice: 0.8750, Epoch Time: 6.14s\n",
      "Saved best model to /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/best_model.pth with training loss: 0.1570\n",
      "Epoch [503/600], Train Loss: 0.1590, Val Loss: 0.1416, Val Dice: 0.8777, Epoch Time: 5.99s\n",
      "Epoch [504/600], Train Loss: 0.1589, Val Loss: 0.1437, Val Dice: 0.8758, Epoch Time: 5.85s\n",
      "Epoch [505/600], Train Loss: 0.1596, Val Loss: 0.1411, Val Dice: 0.8789, Epoch Time: 6.10s\n",
      "Epoch [506/600], Train Loss: 0.1594, Val Loss: 0.1446, Val Dice: 0.8751, Epoch Time: 5.75s\n",
      "Epoch [507/600], Train Loss: 0.1606, Val Loss: 0.1438, Val Dice: 0.8766, Epoch Time: 6.09s\n",
      "Epoch [508/600], Train Loss: 0.1608, Val Loss: 0.1453, Val Dice: 0.8754, Epoch Time: 6.22s\n",
      "Epoch [509/600], Train Loss: 0.1616, Val Loss: 0.1433, Val Dice: 0.8768, Epoch Time: 6.08s\n",
      "Epoch [510/600], Train Loss: 0.1605, Val Loss: 0.1436, Val Dice: 0.8763, Epoch Time: 6.08s\n",
      "Epoch [511/600], Train Loss: 0.1582, Val Loss: 0.1422, Val Dice: 0.8782, Epoch Time: 6.06s\n",
      "Epoch [512/600], Train Loss: 0.1609, Val Loss: 0.1423, Val Dice: 0.8783, Epoch Time: 6.05s\n",
      "Epoch [513/600], Train Loss: 0.1634, Val Loss: 0.1449, Val Dice: 0.8752, Epoch Time: 6.09s\n",
      "Epoch [514/600], Train Loss: 0.1608, Val Loss: 0.1436, Val Dice: 0.8761, Epoch Time: 6.17s\n",
      "Epoch [515/600], Train Loss: 0.1600, Val Loss: 0.1443, Val Dice: 0.8763, Epoch Time: 5.80s\n",
      "Epoch [516/600], Train Loss: 0.1606, Val Loss: 0.1423, Val Dice: 0.8779, Epoch Time: 6.12s\n",
      "Epoch [517/600], Train Loss: 0.1639, Val Loss: 0.1419, Val Dice: 0.8781, Epoch Time: 6.02s\n",
      "Epoch [518/600], Train Loss: 0.1611, Val Loss: 0.1410, Val Dice: 0.8787, Epoch Time: 6.13s\n",
      "Epoch [519/600], Train Loss: 0.1594, Val Loss: 0.1409, Val Dice: 0.8787, Epoch Time: 6.26s\n",
      "Epoch [520/600], Train Loss: 0.1629, Val Loss: 0.1407, Val Dice: 0.8797, Epoch Time: 6.10s\n",
      "Epoch [521/600], Train Loss: 0.1616, Val Loss: 0.1406, Val Dice: 0.8786, Epoch Time: 6.04s\n",
      "Epoch [522/600], Train Loss: 0.1577, Val Loss: 0.1413, Val Dice: 0.8790, Epoch Time: 6.08s\n",
      "Epoch [523/600], Train Loss: 0.1610, Val Loss: 0.1421, Val Dice: 0.8770, Epoch Time: 6.04s\n",
      "Epoch [524/600], Train Loss: 0.1636, Val Loss: 0.1423, Val Dice: 0.8779, Epoch Time: 6.02s\n",
      "Epoch [525/600], Train Loss: 0.1622, Val Loss: 0.1424, Val Dice: 0.8770, Epoch Time: 6.17s\n",
      "Epoch [526/600], Train Loss: 0.1624, Val Loss: 0.1421, Val Dice: 0.8764, Epoch Time: 6.11s\n",
      "Epoch [527/600], Train Loss: 0.1590, Val Loss: 0.1425, Val Dice: 0.8774, Epoch Time: 6.04s\n",
      "Epoch [528/600], Train Loss: 0.1636, Val Loss: 0.1430, Val Dice: 0.8766, Epoch Time: 6.42s\n",
      "Epoch [529/600], Train Loss: 0.1621, Val Loss: 0.1415, Val Dice: 0.8780, Epoch Time: 6.03s\n",
      "Epoch [530/600], Train Loss: 0.1609, Val Loss: 0.1402, Val Dice: 0.8788, Epoch Time: 5.99s\n",
      "Epoch [531/600], Train Loss: 0.1623, Val Loss: 0.1439, Val Dice: 0.8769, Epoch Time: 6.01s\n",
      "Epoch [532/600], Train Loss: 0.1620, Val Loss: 0.1425, Val Dice: 0.8770, Epoch Time: 6.03s\n",
      "Epoch [533/600], Train Loss: 0.1613, Val Loss: 0.1428, Val Dice: 0.8776, Epoch Time: 6.12s\n",
      "Epoch [534/600], Train Loss: 0.1619, Val Loss: 0.1433, Val Dice: 0.8766, Epoch Time: 6.40s\n",
      "Epoch [535/600], Train Loss: 0.1621, Val Loss: 0.1445, Val Dice: 0.8755, Epoch Time: 6.10s\n",
      "Epoch [536/600], Train Loss: 0.1595, Val Loss: 0.1431, Val Dice: 0.8768, Epoch Time: 6.04s\n",
      "Epoch [537/600], Train Loss: 0.1644, Val Loss: 0.1418, Val Dice: 0.8784, Epoch Time: 6.04s\n",
      "Epoch [538/600], Train Loss: 0.1617, Val Loss: 0.1440, Val Dice: 0.8758, Epoch Time: 6.14s\n",
      "Epoch [539/600], Train Loss: 0.1617, Val Loss: 0.1440, Val Dice: 0.8756, Epoch Time: 6.18s\n",
      "Epoch [540/600], Train Loss: 0.1637, Val Loss: 0.1440, Val Dice: 0.8761, Epoch Time: 6.03s\n",
      "Epoch [541/600], Train Loss: 0.1613, Val Loss: 0.1459, Val Dice: 0.8743, Epoch Time: 6.08s\n",
      "Epoch [542/600], Train Loss: 0.1633, Val Loss: 0.1430, Val Dice: 0.8764, Epoch Time: 6.19s\n",
      "Epoch [543/600], Train Loss: 0.1641, Val Loss: 0.1415, Val Dice: 0.8779, Epoch Time: 6.23s\n",
      "Epoch [544/600], Train Loss: 0.1650, Val Loss: 0.1428, Val Dice: 0.8772, Epoch Time: 6.05s\n",
      "Epoch [545/600], Train Loss: 0.1642, Val Loss: 0.1429, Val Dice: 0.8764, Epoch Time: 5.97s\n",
      "Epoch [546/600], Train Loss: 0.1646, Val Loss: 0.1422, Val Dice: 0.8773, Epoch Time: 6.12s\n",
      "Epoch [547/600], Train Loss: 0.1602, Val Loss: 0.1423, Val Dice: 0.8774, Epoch Time: 6.04s\n",
      "Epoch [548/600], Train Loss: 0.1613, Val Loss: 0.1454, Val Dice: 0.8743, Epoch Time: 5.89s\n",
      "Epoch [549/600], Train Loss: 0.1616, Val Loss: 0.1450, Val Dice: 0.8747, Epoch Time: 6.08s\n",
      "Epoch [550/600], Train Loss: 0.1634, Val Loss: 0.1436, Val Dice: 0.8770, Epoch Time: 6.10s\n",
      "Epoch [551/600], Train Loss: 0.1682, Val Loss: 0.1410, Val Dice: 0.8783, Epoch Time: 6.20s\n",
      "Epoch [552/600], Train Loss: 0.1651, Val Loss: 0.1431, Val Dice: 0.8767, Epoch Time: 6.17s\n",
      "Epoch [553/600], Train Loss: 0.1641, Val Loss: 0.1420, Val Dice: 0.8778, Epoch Time: 5.80s\n",
      "Epoch [554/600], Train Loss: 0.1653, Val Loss: 0.1427, Val Dice: 0.8768, Epoch Time: 6.04s\n",
      "Epoch [555/600], Train Loss: 0.1633, Val Loss: 0.1455, Val Dice: 0.8747, Epoch Time: 6.16s\n",
      "Epoch [556/600], Train Loss: 0.1637, Val Loss: 0.1426, Val Dice: 0.8774, Epoch Time: 6.21s\n",
      "Epoch [557/600], Train Loss: 0.1636, Val Loss: 0.1423, Val Dice: 0.8775, Epoch Time: 6.10s\n",
      "Epoch [558/600], Train Loss: 0.1656, Val Loss: 0.1428, Val Dice: 0.8768, Epoch Time: 5.87s\n",
      "Epoch [559/600], Train Loss: 0.1642, Val Loss: 0.1441, Val Dice: 0.8755, Epoch Time: 5.92s\n",
      "Epoch [560/600], Train Loss: 0.1647, Val Loss: 0.1448, Val Dice: 0.8753, Epoch Time: 5.77s\n",
      "Epoch [561/600], Train Loss: 0.1643, Val Loss: 0.1426, Val Dice: 0.8769, Epoch Time: 5.95s\n",
      "Epoch [562/600], Train Loss: 0.1657, Val Loss: 0.1424, Val Dice: 0.8775, Epoch Time: 6.15s\n",
      "Epoch [563/600], Train Loss: 0.1645, Val Loss: 0.1419, Val Dice: 0.8781, Epoch Time: 6.21s\n",
      "Epoch [564/600], Train Loss: 0.1647, Val Loss: 0.1429, Val Dice: 0.8761, Epoch Time: 6.10s\n",
      "Epoch [565/600], Train Loss: 0.1672, Val Loss: 0.1418, Val Dice: 0.8784, Epoch Time: 6.24s\n",
      "Epoch [566/600], Train Loss: 0.1654, Val Loss: 0.1428, Val Dice: 0.8769, Epoch Time: 5.91s\n",
      "Epoch [567/600], Train Loss: 0.1630, Val Loss: 0.1428, Val Dice: 0.8764, Epoch Time: 6.08s\n",
      "Epoch [568/600], Train Loss: 0.1647, Val Loss: 0.1415, Val Dice: 0.8781, Epoch Time: 6.14s\n",
      "Epoch [569/600], Train Loss: 0.1646, Val Loss: 0.1429, Val Dice: 0.8767, Epoch Time: 6.13s\n",
      "Epoch [570/600], Train Loss: 0.1646, Val Loss: 0.1416, Val Dice: 0.8779, Epoch Time: 6.36s\n",
      "Epoch [571/600], Train Loss: 0.1652, Val Loss: 0.1447, Val Dice: 0.8751, Epoch Time: 6.12s\n",
      "Epoch [572/600], Train Loss: 0.1697, Val Loss: 0.1430, Val Dice: 0.8769, Epoch Time: 5.91s\n",
      "Epoch [573/600], Train Loss: 0.1655, Val Loss: 0.1419, Val Dice: 0.8771, Epoch Time: 6.04s\n",
      "Epoch [574/600], Train Loss: 0.1647, Val Loss: 0.1433, Val Dice: 0.8767, Epoch Time: 6.16s\n",
      "Epoch [575/600], Train Loss: 0.1668, Val Loss: 0.1443, Val Dice: 0.8757, Epoch Time: 6.03s\n",
      "Epoch [576/600], Train Loss: 0.1666, Val Loss: 0.1423, Val Dice: 0.8774, Epoch Time: 5.92s\n",
      "Epoch [577/600], Train Loss: 0.1664, Val Loss: 0.1432, Val Dice: 0.8761, Epoch Time: 6.04s\n",
      "Epoch [578/600], Train Loss: 0.1654, Val Loss: 0.1422, Val Dice: 0.8775, Epoch Time: 6.07s\n",
      "Epoch [579/600], Train Loss: 0.1677, Val Loss: 0.1445, Val Dice: 0.8757, Epoch Time: 6.09s\n",
      "Epoch [580/600], Train Loss: 0.1680, Val Loss: 0.1436, Val Dice: 0.8766, Epoch Time: 6.16s\n",
      "Epoch [581/600], Train Loss: 0.1652, Val Loss: 0.1446, Val Dice: 0.8748, Epoch Time: 5.88s\n",
      "Epoch [582/600], Train Loss: 0.1674, Val Loss: 0.1419, Val Dice: 0.8781, Epoch Time: 6.06s\n",
      "Epoch [583/600], Train Loss: 0.1685, Val Loss: 0.1431, Val Dice: 0.8763, Epoch Time: 6.00s\n",
      "Epoch [584/600], Train Loss: 0.1680, Val Loss: 0.1429, Val Dice: 0.8771, Epoch Time: 5.91s\n",
      "Epoch [585/600], Train Loss: 0.1675, Val Loss: 0.1438, Val Dice: 0.8761, Epoch Time: 6.06s\n",
      "Epoch [586/600], Train Loss: 0.1702, Val Loss: 0.1441, Val Dice: 0.8759, Epoch Time: 6.29s\n",
      "Epoch [587/600], Train Loss: 0.1676, Val Loss: 0.1424, Val Dice: 0.8769, Epoch Time: 6.06s\n",
      "Epoch [588/600], Train Loss: 0.1707, Val Loss: 0.1450, Val Dice: 0.8741, Epoch Time: 6.04s\n",
      "Epoch [589/600], Train Loss: 0.1668, Val Loss: 0.1410, Val Dice: 0.8789, Epoch Time: 5.87s\n",
      "Epoch [590/600], Train Loss: 0.1699, Val Loss: 0.1423, Val Dice: 0.8769, Epoch Time: 5.94s\n",
      "Epoch [591/600], Train Loss: 0.1680, Val Loss: 0.1442, Val Dice: 0.8753, Epoch Time: 5.95s\n",
      "Epoch [592/600], Train Loss: 0.1684, Val Loss: 0.1438, Val Dice: 0.8764, Epoch Time: 6.23s\n",
      "Epoch [593/600], Train Loss: 0.1682, Val Loss: 0.1449, Val Dice: 0.8745, Epoch Time: 6.04s\n",
      "Epoch [594/600], Train Loss: 0.1704, Val Loss: 0.1419, Val Dice: 0.8775, Epoch Time: 5.93s\n",
      "Epoch [595/600], Train Loss: 0.1681, Val Loss: 0.1436, Val Dice: 0.8760, Epoch Time: 6.03s\n",
      "Epoch [596/600], Train Loss: 0.1688, Val Loss: 0.1430, Val Dice: 0.8763, Epoch Time: 5.99s\n",
      "Epoch [597/600], Train Loss: 0.1680, Val Loss: 0.1440, Val Dice: 0.8758, Epoch Time: 6.16s\n",
      "Epoch [598/600], Train Loss: 0.1713, Val Loss: 0.1420, Val Dice: 0.8777, Epoch Time: 6.29s\n",
      "Epoch [599/600], Train Loss: 0.1714, Val Loss: 0.1450, Val Dice: 0.8752, Epoch Time: 6.16s\n",
      "Epoch [600/600], Train Loss: 0.1704, Val Loss: 0.1426, Val Dice: 0.8771, Epoch Time: 6.16s\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx4awOGAsqt_"
   },
   "source": [
    "## Test model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce4eePUYnI7P",
    "outputId": "37bd10a9-e6e4-4326-e8cc-004c4468f3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/last_model.pth\n",
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the path to the saved model\n",
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/SIGN/mri/\"\n",
    "model_save_path = os.path.join(save_path, 'last_model.pth')\n",
    "\n",
    "# Instantiate the model (make sure the model architecture is defined in a previous cell)\n",
    "# Assuming 'model' is already defined and is an instance of your ViT class\n",
    "# model = VisionTransformer(...) # If not already defined, define it here with the correct parameters\n",
    "\n",
    "# Load the saved state dictionary\n",
    "if os.path.exists(model_save_path):\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    print(f\"Model loaded successfully from {model_save_path}\")\n",
    "else:\n",
    "    print(f\"No model found at {model_save_path}\")\n",
    "\n",
    "# Move the model to the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ki4NlOIonIgl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(model, testloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            loss, correct, _ = evaluate_batch(images, labels, model, criterion, device)\n",
    "            test_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += 1\n",
    "\n",
    "    # Calculate average test loss and accuracy\n",
    "    average_test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test DICE: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyNO4iHariL1"
   },
   "source": [
    "## CVE encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SeNE_Gv0shW_"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.ssim_eval import ssim\n",
    "from song_code_reproduction.src.pruning import prune_model_global_l1\n",
    "\n",
    "from song_code_reproduction.src.sign_encoding_loss import (select_all_params, bytes_to_images_torch,\n",
    "                                                           decode_bytes_from_given_model, bytes_to_images_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ssim(recovered_imgs, memorization_set, memorization_size):\n",
    "    ssim_scores = []\n",
    "    for i in range(len(recovered_imgs)):\n",
    "        with torch.no_grad():\n",
    "            src = (memorization_set[i][0].unsqueeze(0)*255).float()\n",
    "            dec = recovered_imgs[i].unsqueeze(0).float()\n",
    "            ssim_score = 0.5*(1+ssim(dec, src))\n",
    "            ssim_scores.append(ssim_score)\n",
    "    ssim_scores = torch.tensor(ssim_scores)\n",
    "    return ssim_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zeWS5y46tO-h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded bytes: 491520  can reconstruct up to 10 images\n",
      "Reconstructed tensor: torch.Size([10, 3, 128, 128]) torch.uint8 0 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded = sign_penalty.decode_bytes_from_model()\n",
    "\n",
    "H, W, C, order = 128, 128, 3, \"CHW\"\n",
    "per_image_bytes = H * W * C  # 784\n",
    "max_images = len(decoded) // per_image_bytes\n",
    "print(f\"Decoded bytes: {len(decoded)}  can reconstruct up to {max_images} images\")\n",
    "\n",
    "N = min(memorization_size, max_images)\n",
    "if N == 0:\n",
    "    print(\"Not enough capacity for a full image. Increase subset size or reduce redundancy.\")\n",
    "else:\n",
    "    imgs = bytes_to_images_torch(decoded, n=N, h=H, w=W, c=C, order=order, device=\"cpu\")\n",
    "    print(\"Reconstructed tensor:\", imgs.shape, imgs.dtype, imgs.min().item(), imgs.max().item())\n",
    "    # Optionally visualize\n",
    "    import matplotlib.pyplot as plt\n",
    "    grid = torch.cat([imgs[i] for i in range(min(16, N))], dim=2)[0]\n",
    "    plt.imshow(grid.numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Decoded (concatenated) samples\")\n",
    "    plt.show()\n",
    "    \n",
    "def decode(model, sign_penalty, size = (28, 28, 1), order=\"CHW\"):\n",
    "    \n",
    "    subset_selector = select_all_params     # or select_linear_head_params  must match training\n",
    "    k = sign_penalty.k\n",
    "    B_bits = int(sign_penalty.B_bits.item())\n",
    "    \n",
    "    decoded = decode_bytes_from_given_model(\n",
    "        model=model,\n",
    "        subset_selector=subset_selector,\n",
    "        k=k,\n",
    "        B_bits=B_bits,\n",
    "    )\n",
    "    \n",
    "    # 3) Turn bytes into images (MNIST shapes)\n",
    "    H, W, C = size \n",
    "    per_image_bytes = H * W * C\n",
    "\n",
    "    max_images = len(decoded) // per_image_bytes\n",
    "\n",
    "    imgs = bytes_to_images_torch(decoded, n=max_images, h=H, w=W, c=C, order=order, device=\"cpu\")\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning:\n",
      "SSIM: 0.8223\n",
      "Test Loss: 0.1544, Test DICE: 0.8675\n",
      "\n",
      "After pruning:\n",
      "SSIM: 0.5101\n",
      "Test Loss: 0.1564, Test DICE: 0.8672\n"
     ]
    }
   ],
   "source": [
    "imgs = decode(model, sign_penalty, size=(128, 128, 3), order=\"CHW\")\n",
    "ssim_before_pruning = calc_ssim(imgs, memorization_set, memorization_size)\n",
    "print(\"Before pruning:\")\n",
    "print(f\"SSIM: {ssim_before_pruning:.4f}\")\n",
    "test_model(model, testloader, device)\n",
    "\n",
    "pruned_model = prune_model_global_l1(model, 0.2)\n",
    "print()\n",
    "\n",
    "print(\"After pruning:\")\n",
    "imgs = decode(pruned_model, sign_penalty, size=(128, 128, 3), order=\"CHW\")\n",
    "ssim_after_pruning = calc_ssim(imgs, memorization_set, memorization_size)\n",
    "print(f\"SSIM: {ssim_after_pruning:.4f}\")\n",
    "test_model(pruned_model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX3iP0J8mXte"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
