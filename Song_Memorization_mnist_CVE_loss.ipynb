{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oyDhcmIBaaHB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QAWX2eoL2kvp"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.mnist_fcn import FCN_parameters, FCModel, LEARNING_RATE, WEIGHT_DECAY\n",
    "\n",
    "from song_code_reproduction.src.org_cve_loss import CVELoss, reconstruct_from_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JfmFbzz6ja81"
   },
   "outputs": [],
   "source": [
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/CVE/\"\n",
    "\n",
    "memorization_size = 100\n",
    "\n",
    "# Training Params\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 60 # Example number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y853H_UcbQSo",
    "outputId": "7a01ac52-1f28-4c01-f63b-42acde9c5830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n",
      "Number of images in training set: 48000\n",
      "Number of images in validation set: 12000\n",
      "Number of images in test set: 10000\n",
      "Number of images in memorization set: 100\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Subset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations for training with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define transformations for validation, testing, and memorization set (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mem_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "# Download the full CIFAR100 training dataset\n",
    "full_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=eval_transform)\n",
    "\n",
    "\n",
    "# Split the full training set into training and validation indices\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "train_indices, val_indices = random_split(range(len(full_trainset)), [train_size, val_size])\n",
    "\n",
    "# Create training and validation datasets using indices and applying appropriate transforms\n",
    "train_dataset = Subset(full_trainset, train_indices.indices)\n",
    "val_dataset = Subset(full_trainset, val_indices.indices)\n",
    "\n",
    "# Apply transforms to the datasets\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = eval_transform\n",
    "\n",
    "if memorization_size > len(full_trainset):\n",
    "    memorization_size = len(full_trainset)\n",
    "memorization_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mem_transform)\n",
    "memorization_indices = torch.randperm(len(full_trainset))[:memorization_size]\n",
    "memorization_set = Subset(memorization_set, memorization_indices)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "print(f\"Number of images in training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in validation set: {len(val_dataset)}\")\n",
    "print(f\"Number of images in test set: {len(testset)}\")\n",
    "print(f\"Number of images in memorization set: {len(memorization_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "udoiZLHFeET8"
   },
   "outputs": [],
   "source": [
    "model = FCModel(**FCN_parameters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xbqv9LacHj4",
    "outputId": "f44f6a36-efeb-475f-d621-649d53012d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hyperparameters and objects defined.\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 60\n",
      "Loss Function: CrossEntropyLoss\n",
      "Optimizer Type: AdamW\n",
      "Scheduler Type: CosineAnnealingLR\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cve_loss = CVELoss(model=model,\n",
    "                   dataset=memorization_set,\n",
    "                   K=100*28*28,\n",
    "                   device=device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr= LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(\"Training hyperparameters and objects defined.\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")\n",
    "print(f\"Optimizer Type: {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler Type: {type(scheduler).__name__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HTtpo-aXe_UL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    # loss = criterion(outputs, labels) + cve_loss()\n",
    "    loss = criterion(outputs, labels) + cve_loss()\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_batch(images, labels, model, criterion, device):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Calculate accuracy\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      correct = (predicted == labels).sum().item()\n",
    "\n",
    "    return loss.item(), correct, labels.size(0)\n",
    "\n",
    "def main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path):\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion, device)\n",
    "            running_loss += loss\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in valloader:\n",
    "            loss, correct, total = evaluate_batch(images, labels, model, criterion, device)\n",
    "            val_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += total\n",
    "\n",
    "        epoch_val_loss = val_loss / len(valloader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, '\n",
    "              f'Val Accuracy: {accuracy:.4f}, '\n",
    "              f'Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model to {model_save_path} with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        model.train() # Set model back to training mode\n",
    "\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uguhGoO_fo7g"
   },
   "outputs": [],
   "source": [
    "# main_train_loop(model, trainloader, valloader, optimizer, criterion, scheduler, num_epochs, device, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx4awOGAsqt_"
   },
   "source": [
    "## Test model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce4eePUYnI7P",
    "outputId": "94d3e775-c632-4793-a855-bc2f38f89ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /dt/yisroel/Users/Data_Memorization/song_memorization/CVE/best_model.pth\n",
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the path to the saved model\n",
    "save_path = \"/dt/yisroel/Users/Data_Memorization/song_memorization/CVE/\"\n",
    "model_save_path = os.path.join(save_path, 'best_model.pth')\n",
    "\n",
    "# Load the saved state dictionary\n",
    "if os.path.exists(model_save_path):\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    print(f\"Model loaded successfully from {model_save_path}\")\n",
    "else:\n",
    "    print(f\"No model found at {model_save_path}\")\n",
    "\n",
    "# Move the model to the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki4NlOIonIgl",
    "outputId": "6903fede-5718-4bf1-d7cc-fdb1b8262ba6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(model, testloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            loss, correct, total = evaluate_batch(images, labels, model, criterion, device)\n",
    "            test_loss += loss\n",
    "            correct_predictions += correct\n",
    "            total_predictions += total\n",
    "\n",
    "    # Calculate average test loss and accuracy\n",
    "    average_test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyNO4iHariL1"
   },
   "source": [
    "## CVE encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SeNE_Gv0shW_"
   },
   "outputs": [],
   "source": [
    "from song_code_reproduction.src.ssim_eval import ssim\n",
    "from song_code_reproduction.src.pruning import prune_model_global_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EUDKM8tmHJdA"
   },
   "outputs": [],
   "source": [
    "def calc_ssim(memorization_size, memorization_set, recon):\n",
    "  ssim_scores = []\n",
    "  for i in range(memorization_size):\n",
    "    with torch.no_grad():\n",
    "      ext_img = recon[i].unsqueeze(0)\n",
    "      src_img = memorization_set[i][0].unsqueeze(0)\n",
    "      ssim_score_org = 0.5*(ssim(src_img,ext_img)+1)\n",
    "      ssim_score_inv = 0.5*(ssim(src_img, 1-ext_img)+1)\n",
    "      ssim_score = max(ssim_score_org, ssim_score_inv)\n",
    "      ssim_scores.append(ssim_score)\n",
    "  ssim_scores = torch.tensor(ssim_scores)\n",
    "  return ssim_scores.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEn_5tiNhvEQ",
    "outputId": "03c0de66-463e-4eb0-bb04-02baae15584a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM before pruning: 0.9853981137275696\n",
      "Test Loss: 0.1121, Test Accuracy: 0.9800\n",
      "SSIM after pruning: 0.5067136287689209\n",
      "Test Loss: 0.1105, Test Accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "recon = reconstruct_from_params(model=model,\n",
    "                                K=100*28*28,\n",
    "                                item_shape=(1,28,28),\n",
    "                                value_range=(0.,1.))\n",
    "ssim_before = calc_ssim(memorization_size=memorization_size, memorization_set=memorization_set, recon=recon)\n",
    "print(f\"SSIM before pruning: {ssim_before}\")\n",
    "test_model(model, testloader, device)\n",
    "\n",
    "pruned_model = prune_model_global_l1(model, 0.2)\n",
    "\n",
    "recon = reconstruct_from_params(model=pruned_model,\n",
    "                                K=100*28*28,\n",
    "                                item_shape=(1,28,28),\n",
    "                                value_range=(0.,1.))\n",
    "ssim_after = calc_ssim(memorization_size=memorization_size, memorization_set=memorization_set, recon=recon)\n",
    "print(f\"SSIM after pruning: {ssim_after}\")\n",
    "test_model(pruned_model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZdNZIrJftui",
    "outputId": "7efd7df9-e7ec-4fe1-899e-f9cdf28056e4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7bEFAr0tLUH"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeWS5y46tO-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-In0VOsBy-yE",
    "outputId": "44428959-3c46-4af2-810a-90ab654f511e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8VhhSKK0J8V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShM0BqseKrR8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
